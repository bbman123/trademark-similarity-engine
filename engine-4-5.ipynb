{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d921c3b",
   "metadata": {},
   "source": [
    "# Trademark Similarity Engine: Hybrid CNN + SVM with Multilingual Linguistic AI\n",
    "\n",
    "## PhD Project Overview\n",
    "This notebook implements a trademark similarity classifier/ranker that identifies \"confusingly similar\" marks using:\n",
    "- **Hybrid Architecture**: Character-level CNN for feature extraction + SVM for classification\n",
    "- **Multilingual Support**: English, Hausa, and Yoruba\n",
    "- **Advanced Linguistic Features**: Synonyms, antonyms, phonetic similarity, cross-lingual equivalents\n",
    "\n",
    "## Project Structure\n",
    "1. Data Loading & Exploration\n",
    "2. Text Preprocessing Pipeline\n",
    "3. CNN Architecture & Training\n",
    "4. Linguistic Feature Engineering (Synonyms, Phonetics, Translations)\n",
    "5. Feature Combination & SVM Training\n",
    "6. Evaluation & Metrics\n",
    "7. Similarity Ranking Prototype\n",
    "8. Explainability Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78120d",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Exploration\n",
    "\n",
    "Let's begin by loading the trademark dataset and understanding its structure, distributions, and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65f08fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n",
      "NumPy version: 1.24.3\n",
      "Pandas version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization defaults\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b0f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "    wordmark  class     goods_services  label pair_id\n",
      "0   TechFlow      9           Software      1       A\n",
      "1    TekFlow      9  Software products      1       A\n",
      "2   DataSync     42        IT Services      1       B\n",
      "3   DataLink     42      Data services      1       B\n",
      "4  QuickMart     35             Retail      1       C\n",
      "5   FastMart     35       Retail store      1       C\n",
      "\n",
      "Dataset shape: (6, 5)\n",
      "\n",
      "Column types:\n",
      "wordmark          object\n",
      "class              int64\n",
      "goods_services    object\n",
      "label              int64\n",
      "pair_id           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load trademark dataset\n",
    "# TODO: Replace with your actual dataset path\n",
    "# Expected columns: 'wordmark', 'class', 'goods_services', 'label', 'pair_id' (optional)\n",
    "\n",
    "# For demonstration, create a sample structure\n",
    "# In production, use: df = pd.read_csv('your_trademark_data.csv')\n",
    "\n",
    "sample_data = {\n",
    "    'wordmark': ['TechFlow', 'TekFlow', 'DataSync', 'DataLink', 'QuickMart', 'FastMart'],\n",
    "    'class': [9, 9, 42, 42, 35, 35],\n",
    "    'goods_services': ['Software', 'Software products', 'IT Services', 'Data services', \n",
    "                       'Retail', 'Retail store'],\n",
    "    'label': [1, 1, 1, 1, 1, 1],  # 1 = similar pairs\n",
    "    'pair_id': ['A', 'A', 'B', 'B', 'C', 'C']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab01591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total records: 6\n",
      "Unique wordmarks: 6\n",
      "Unique classes: 3\n",
      "\n",
      "--- Label Distribution ---\n",
      "label\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Class Distribution ---\n",
      "class\n",
      "9     2\n",
      "42    2\n",
      "35    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Wordmark Length Statistics ---\n",
      "count    6.000000\n",
      "mean     8.000000\n",
      "std      0.632456\n",
      "min      7.000000\n",
      "25%      8.000000\n",
      "50%      8.000000\n",
      "75%      8.000000\n",
      "max      9.000000\n",
      "Name: wordmark_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic dataset statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal records: {len(df)}\")\n",
    "print(f\"Unique wordmarks: {df['wordmark'].nunique()}\")\n",
    "print(f\"Unique classes: {df['class'].nunique()}\")\n",
    "\n",
    "print(\"\\n--- Label Distribution ---\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "print(\"\\n--- Class Distribution ---\")\n",
    "print(df['class'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n--- Wordmark Length Statistics ---\")\n",
    "df['wordmark_length'] = df['wordmark'].str.len()\n",
    "print(df['wordmark_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0bb416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAPdCAYAAACOcJpIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADP50lEQVR4nOzdd3xO5+P/8XemkSiCoj5VLRU1EyN2raJWKYqOtHaVUkqMao3aRVGj9o7WqL1pUa09WjMUtWsmRkISkfv3R34539ySnOzcibyej0cej9xnXue6T+5c531f5zp2FovFIgAAAAAAAAAAECN7WxcAAAAAAAAAAIC0jCAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHcBzafLkyXJ3d5e7u7sOHTqUrNuO3G7btm2TdbtXr141tj1w4EDTZffv328sG/WnVKlSql69urp27ao9e/aYrjdt2rQklffs2bMJWt7b21vu7u4qXry4MW3lypVGedasWZOk8pgJCgrS1atXrabVrl1b7u7uqlu3bortFwAAILX1798/xnZiTD8rV660dXG1b9++ONvtq1evVtOmTVWqVClVqlRJ/fr1082bN+Pcdnzrwd3dPbkPK0Zr1qxJU3WfVMnZlr9x44ZGjx6thg0bytPTU2XKlFHDhg01ZsyYGN/rlLomAwAzBOkA8BwJDQ3VrVu39Ouvv6pdu3aaMWNGsu/j33//1eeff64uXbok+7aTW1hYmH766SfVq1dPBw4csHVxAAAAEMXt27c1ePBg02UWL16sfv36yc/PT6GhoQoICNDq1av1wQcfKDAwMJVKipS0fft2NWjQQPPmzdP58+f16NEjBQcH6/z585o7d64aN26sw4cP27qYACBHWxcAAJA0HTp00Mcff6ynT58qKChIR48e1aRJk3T37l1NmDBBpUqVUpUqVSRJnp6e2rVrlyTJ1dU1Ufv79NNPdenSJRUoUCBB602aNEmhoaGys7NL1H4TY+PGjRoyZEiM85YuXaqnT5/KwcEh1coDAACQ0gYMGKCePXsar+fNm6f58+dLkqZMmaJSpUoZ87Jnz57Kpfs/x44dU58+fXTp0qVYlwkMDNT48eMlSaVLl9bw4cN15MgRDRkyRFevXtXcuXPVo0ePWNePbPdGat26tW7cuKECBQpoyZIlyXMgSJK///5bPXv21JMnT5QjRw717NlTlSpV0sOHD+Xr66vVq1frwYMH6t69u7Zu3ZroaxgASA4E6QCQzrm6uipfvnzG66JFi+qNN97Qe++9J4vFoilTphhBurOzs9WyiWGxWBK1npubW5L2mxhmZc2TJ08qlgQAACB1ZM+e3Sogjxo85syZM8ltweTg4+Oj9evXKzw8XHZ2drG22Xbs2KFHjx5Jkrp162YM57F8+XKdPHlSGzZsMA3Snz3WyA4UDg4OaaIeII0aNUpPnjyRo6Oj5syZo5IlSxrzSpcurZCQEG3atEn+/v7asWOHmjRpYsPSAsjoGNoFAP6/1atXq02bNqpYsaJKliypKlWqqEuXLvrrr79iXWfv3r167733jLHJR44cGeMtpmvXrlWLFi1UpkwZlStXTp988on+/PPPFDuW0qVLq3Tp0pKkI0eOKCAgQFLsY6Tfv39fo0aNUt26dVWqVCmVLFlSderU0bBhw3T//n1jOXd3d12+fFmSdO3aNbm7u8vb21uS9bj0Bw4cUOPGjVWyZEk1adJET58+jXGM9KiePn2qKVOmqGbNmipVqpTeffddbdiwwWoZs3EYnx3zfPLkyerbt68xf8CAAXJ3d9f+/ftjXD6qzZs3q23btqpYsaJKlSqlhg0batKkSdHe26jHHBAQoIkTJ6pWrVoqVaqUmjRponXr1sX2FgEAAKQZiWn73Lx5U8OHD1fVqlVVpkwZffTRR/F+NtGOHTsUHh6u+vXr6+OPP451uRMnThi/R21DRoatFy9eTLbhXeJqy0oJu15Yt26dmjVrplKlSqlmzZqaOnWqwsPDY91/fK4Xorbl//jjD82ZM0dvvfWWSpcurRYtWujgwYN68uSJpk6dqlq1aql06dJ699139dtvv0XbX3yPJXJ/o0aN0siRI+Xp6amyZcvql19+ifE47ty5ozp16sjd3V0lSpTQ9u3bYz3mixcv6ujRo5Kk6tWrW4XokXr27KmpU6dq79698QrRDx8+rC5duhjb8/Ly0vvvv6/Vq1dbLRcSEqIpU6aoUaNGKl26tEqUKKEaNWqof//++u+//6yWje+1UqTff/9d3t7e8vT0lKenp9q0aaP169dHW+78+fPq2bOnqlWrphIlSsjDw0NNmzbV7NmzE915CUDKokc6AEhauHChRowYYTXt7t272rFjh/bs2aO1a9eqUKFCVvPPnDmjjh07KiwsTJJ069YtLViwQEePHpWvr6+cnZ0lSePGjdOsWbOs1t23b5/279+vYcOG6b333kuRYypevLiOHTsmi8UiPz8/Va5cOcblwsPD1a5dO508edJq+tWrV7V48WIdPXpUy5Ytk6Nj/P9ldOvWTQ8ePJAkvf766/EaPmXChAm6deuW8frUqVP68ssvdfv27VR9iNCQIUP0008/WU07f/68pk2bps2bN2vRokXKnTt3tPU+//xzq4vHs2fPqk+fPsqbN6+8vLxSvNwAAACJkdi2T6dOnXTmzBnj9cGDB9W2bVv9+OOPql69uuk+y5cvr1atWql27dqaPHlyrMtdu3bN+D1nzpwx/n79+nUVLVrUdH8JFVNbNiHXC3PmzNF3331nLPfff//phx9+0Isvvhjj/hJzvTBmzBidPXvWeH3ixAl17txZZcqU0d69e43pp06d0ueff66VK1eqWLFikhJ37bNy5UqjTqSIISOfDd2DgoLUuXNnXb16VXZ2dho5cqTeeuutGI9ZktX6Hh4eMS5TqFChaGWJzbFjx9SuXTuFhIQY0+7fv68jR47oyJEjkqRmzZpJkr788stoIf+NGze0atUqHThwQCtXrlSOHDkSfK20ZMkSffvtt1ZB+NGjR3X06FGdP39eX3zxhaSIc7t169Z6+PChsVxYWJj8/Pzk5+enGzdu6Ouvv47XcQNIPfRIB5DhhYeHy9fXV1JEA27VqlXasmWLOnXqJCmit0JMvcf9/f1VvXp1rVy5Ur6+vipRooSkiAbc8uXLjd8jG8U1atTQypUrtXr1atWuXVsWi0XDhw/X3bt3U+S4ot7Se+/evViXO3XqlNEwbNeunTZt2qSNGzfqo48+kiTdvHnT6Cmya9cuY2z0fPnyadeuXZo0aVK0bWbKlEm+vr5aunSpOnfuHK/y+vv7a8CAAdq4caOGDx+uzJkzS4oI2CN71CdEu3btrBqfAwYM0K5du+Tp6RnrOhs3bjQuJEuUKKH58+dr7dq1RpB/4cIF9evXL8Z1//nnH02aNEnr1q1T48aNjemrVq1KcNkBAABSQ1LaPleuXNGIESO0ceNG9e7dW3Z2dnry5IkGDx5s9OCOzfTp01W7du04yxc5rIu9vb2cnJyM6VF/DwoKinM7CfVsWzYh1wv+/v6aOHGiJClr1qxGHfXr1y/Gdn9irxcuXLig4cOHa8OGDUZdPnr0SPv27dOAAQO0adMmtWrVSlLEnZ9bt26VlPhrnwcPHsjb21ubN2/WpEmT9Nprr1nNf/r0qXr06GFcV3zzzTdq2rSpaT3fuXPH+D05hoFcunSpQkJClDNnTs2dO1fbt2/XhAkTZG8fEX1F9sz39/c3QvTGjRtr3bp12rp1q3r16iUp4pyKrIOEXCvdvHlTI0eOlMViUenSpbVkyRJt2LDB+CLkxx9/lJ+fnyRpy5YtRog+fvx4bd++Xb/88ou8vLxkb2+v3bt38zBdIA2iRzqADM/e3l5btmzRjRs35OzsLDc3NwUGBlo1DmMKorNly6Zx48YZ406OHTtWDRs2lCTt3LlTH374odUtfN27d1euXLkkST169NBvv/2m4OBgbdq0yWiIJaeovSDMLmaiBu6nT5+Wn5+fvLy89NVXX6lHjx5W8/PlyxevsSU/+OADlS9fPkHlbdq0qXHRVrhwYV28eFGzZ89WcHCw9u7da9RtfLm6uuqFF14wXr/wwgtxjoW5ePFiSREXTz/++KPy5s0rKSKEv3Tpknbs2KE//vhD//77r1599VWrdbt06aK3337bWD7yvb99+3aCyg0AAJBaktL26dy5s1q2bCkpou126tQpbdq0SdeuXZOfn5/RySQpbDW8RUxt2fheL+zZs0ehoaGSpA4dOljV0cmTJ6MN8ZHY64U6deoYAW3r1q2NkLhq1apGm/rDDz/UsmXLJMkI4xN77ZM1a1b5+PgoU6ZM0c4FKWJonOvXr0uSPv74Y3344YfRlnlW1KFuzIa9ia8RI0aoX79+un//vl5++WU9efJEd+7ckaurqx48eGAMw5I1a1ZlypRJISEh+vfff3Xy5ElVrFhRXbp0UatWraxC/YRcK23evFlPnjyRJH366adGB6SuXbtq/fr1evz4sdasWaNixYopR44cxnr79+9Xzpw55eHhoRkzZsje3t7oVAQgbSFIBwBFNNz+/vtv7dixQ3/99ZcuXboUZ8OucOHCVg9vinwdGBhojKt38eJFY35kI/pZz94mmFyi3iYYtYH3rJdfflldu3bVjz/+qH379mnfvn2SpIIFC6patWpq3bq1cRtofCXm9trIMd0jRb2989lxCmOSHBdap0+flhTxXkZeSEaqUqWKduzYISliWJ9nLyCiHnPU240jh/4BAABIa5LS9ilbtqzVa09PT23atElSxLAXyRGkZ82aVVJEWzwsLMwYPiMyqJYkFxeXJO/nWTG1ZeN7vRAZJksxt2+fDdITe70Q9f2IWgdRyx51etQ2aWKufQoWLKhMmTLFWD7J+rgPHTqk8PBwoyd4bKK2mWO7S9discjOzs50O1FduHBBGzZs0JEjR/TPP/9YDfMSeVyZM2fW119/raFDh+rkyZPq37+/pIhOQ5UrV1bLli2NL1IScq0U9b3s1q1bjOWLHPe/cePG2rBhg/744w8tW7ZMy5Ytk4ODg4oVK6batWurTZs2MQ6pBMC2GNoFQIZnsVjUuXNn9ejRQ+vXr1exYsU0cOBATZkyxXS9yN4GUUU27iMbjfEZG9zf3z8RpY5b1DEr4wrCv/jiC23YsEGff/65ypYtq0yZMuny5ctasmSJ3n33XeMiKr6ifsEQX88GzlHrLqZ6fLaBH7WRnFiR719MjfWoQX1M86P2GonP+w4AAGBrSWn7RA2z47N8YuTPn9/4PWov6ajD/r300kvJsq+onm3LJvZ64dmOHjEFy4m9Xogaaket78gvH56dHrVMiTmWbNmyxVlOd3d3SRHDoaxYsSLO5cuUKWP8HtMDWyVp69atqlOnjoYPH2588ROb6dOnq3Xr1lq4cKFcXFzUtWtXzZ8/P9qXRJLUqlUrbdu2TX369FHlypWVNWtWY4z0Dz/80Bj+Ror/tVJ83svIc9fZ2Vlz5szRggUL5O3traJFi8pisejkyZOaPHmymjRpYvWMAABpAz3SAWR4+/fv1+7duyVFPBW+Y8eOkiLGKzRz7tw5BQQEGD0prly5YjTwCxYsKEl65ZVXjOX//PNPo1dBYGCgLl++rFdffVVZsmRJ1uORInpDRDZGPT09lSdPnliXffDggc6ePasLFy7oww8/VPfu3fXkyRMdPnxYnTp1UmhoqBYtWqRatWpJ+r8GuVkP8IQ8mDTSwYMHrW5ZPX78uPH7yy+/LEnGA1wlWY0Z+OjRoxhvQY168RCfHuuFCxfW0aNHde7cOd28edOq0R31oU1vvPFGnNsCAABI65LS9jl48KDVQ0Wjtt0i28JJVbx4ceP3kydPqkaNGpIiglopold2YjpwxOXZtmxCrheiHvuxY8eMMksyHngZVWpfLyT22ieu9n3Dhg313XffqXnz5jp79qwmTJigt99+22qoxWcVLVpUxYsX16lTp/Tnn3/qxIkTKlmypDH/6dOnmjdvnq5evapFixapXLlysbbDg4ODNXXqVEkRY83PnDlTUkRnnWfH0Q8KCtK5c+d04cIF1a9fX506ddLTp0918uRJde3aVbdv39bChQv14YcfJuhaKep7uWzZMuOLgidPnujUqVNWdzTfuHFD586d03///Wc81ykwMFArVqzQqFGj5O/vr3Xr1qlLly6m9Q4gdRGkA3junThxIlqPmUjFihWzaljt3LlTb775pvz9/fXdd98Z02ManiMkJERdunSRj4+PnJ2dNXLkSGNe5NPpmzRponnz5kmS+vTpo549e8rZ2VkzZ87Upk2bZGdnp6lTp6pOnTqJPr7AwEDduHFDkvT48WOdPn1aEydONHpsf/bZZ6br79y5Uz4+PpKkX3/9VZ9//rmyZ8+u//77z9hG1IZzZO+Xe/fu6fTp07JYLFYXOYm1efNmTZgwQY0aNdLp06c1f/58SRE9gipWrChJVhd3v/zyi5o0aSJ7e3uNGjUqxnHgo/bUOXXqlEqVKqXcuXPH+jCjFi1a6OjRowoJCVHXrl3l4+MjNzc3rVq1yuhp8uabbybbxSEAAIAtJaXts2DBAuXPn19eXl7avXu3MaxLoUKFjJ7JSVWzZk1lzpxZwcHBmjZtmvLnz6+//vrLaniM1JCQ64Vq1arJxcVFQUFBmj17tvLly6eyZcvqt99+08aNG6NtOzWuFxJ7LAlRs2ZNOTk5qX///mrfvr38/f01ZcoUffXVV6brffXVV2rbtq3CwsLUsWNH9e7dW15eXrp9+7ZmzZplPMizWLFiqlevXqzbefLkiXHNd+rUKR08eFDZsmXTrFmzjA44kcfl5+enDz74QFJEr/i+ffsqb968unXrlnGXa+T1T0KulerVq6exY8cqJCREQ4YMUb9+/eTm5qZly5Zp0aJFkqSvv/5a3t7emjJlipYvXy5Junz5spo1ayZJxnVd1O0CSDv4qwTw3Bs1alSs86ZOnary5csrV65cunv3rg4ePKgmTZpEWy7qE+UjlShRQsePH4/2IJ2KFSsa2yhRooTef/99/fTTT9q7d69Vzx5Jql69utHTO7HmzJmjOXPmxDive/fuVr1gYtKwYUNt2LBBO3fuNH6icnZ2VufOnY3XxYoV09mzZ/Xo0SM1a9ZMRYoU0YYNG5J0DFJEI3b69OmaPn261fQBAwYYPTfKlCmj//3vf7p69apOnz6tSpUqyWKxyMXFRUWKFNG5c+es1o3aY2Xx4sVavHixJk6cqAYNGsRYhpYtW+rAgQNau3atTpw4oU8++cRq/muvvWZ6PgEAAKQnSWn75MyZU0OGDLGa5uTkpKFDhybb0C5ubm7q1auXRo0apb/++suqnV6wYEHjoZoprVy5cvG+XnB1ddXAgQM1cOBABQcHG72NpYhrg2fHO0+N64XEHktiVK1aVTVq1NCuXbvk6+ur1q1bq3DhwrEuX6FCBY0dO1b9+/dXQECAVX1FKlCggCZPnmw6dEq2bNlUpUoV7dmzR7dv3472cFbp/46rXLlyat26tZYuXaq///472vWcnZ2dMcZ5Qq6V8ubNq+7du2vcuHE6depUtL+nEiVKqEWLFpIirtP27dunK1euaObMmUYP+kgvvfSSmjdvHuvxArANxkgHkOHlyJFDc+fOVbVq1fTCCy8oW7ZsKlWqlL777jtVrVpVkrRr165oPZ4rVqyouXPnytPTU5kyZVLevHnVsWNHzZw506qRN3jwYA0fPlweHh5ycXFRlixZVLRoUfn4+GjatGlxPoQnIZycnPTiiy+qXr16WrhwoT7//PM413F0dNTkyZM1aNAglS5dWjly5JCjo6Py5Mmj+vXr6+effzYetiNFNPqqVq0qV1dXubq6Jtu4lEOHDtUXX3yhAgUKyNnZWSVKlNDUqVOtHrrk7OysuXPnqlatWnJxcZGrq6vq1aun5cuXx9hAL1iwoHx8fPTKK6/IyclJBQoUMH1Ikp2dncaOHauJEyeqatWqypEjh5ycnPTqq6+qa9euWr58OQ/9AQAAz42ktH1Gjhypdu3ayc3NTZkzZ5aXl5cWLVqkSpUqJWsZ27Ztq/Hjx6t48eJydnZWjhw51KxZM/n6+qbIsC4xSej1QosWLTR16lSVLFlSzs7Oeumll9S9e3erO1ijSs3rhcRe+yREv3795OjoqLCwsFiPOarIsPqDDz5QwYIF5ezsrCxZsqhYsWLq3r271q5dG687QsePH6+WLVsqT548ypIli1577TV17drVuCa6fPmy0fFm6NChGjt2rCpUqKDcuXPL0dFROXPmVI0aNTRv3jw1bNhQUsKvlTp16qSpU6eqYsWKeuGFF5QpUyYVKlRIXbp00cKFC40x7PPmzatly5bp008/VZEiReTi4iInJycVLFhQH330kZYvXx7rXbQAbMfOEp9BYwEAAAAAQIY2efJk46GUvr6+VgEiAADPO3qkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJhgjHQAAAAAAAAAAEzQIx0AAAAAAAAAABME6QAAAAAAAAAAmHC0dQGS2+3bD21dBAB4bri5ucjfP8jWxQCA50KePNlsXQSbevo0nP8pScT/5eRBPSYddZh01GHSUYdJRx0mHXWYPGxdj/Ftp9MjHQAQIzs7ycHBXnZ2ti4JAOB5wP+UpOH/cvKgHpOOOkw66jDpqMOkow6TjjpMHumpHgnSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADARLoI0u/du6e+ffuqYsWKqlChgrp27apbt27ZulgAAAAAAAAAgAwgXQTp3bt316NHj7Rt2zbt2LFDDg4O+uabb2xdLAAAAAAAAABABuBo6wLE5cSJE/r777+1Z88eubq6SpKGDRum27dvx7qOnV1qlQ4Anl+Rn6V8pgIAAAAAgIwuzQfpx44dU5EiRbRs2TL99NNPevz4sapXr65+/frFuLybm4scHNJFR3tkYPWHbbB1EQDgubHlm0a2LgIAAAAA4DmX5oP0+/fv68yZMypZsqRWrVql4OBg9e3bV/369dOMGTOiLe/vH0TvSQAAMpA7dx7aughAvOTOnc3WRQAAAACQSGk+SHd2dpYkDRw4UJkyZZKrq6t69uypVq1aKSgoSC4uLtHWsVhSu5QAAMBW+L8PAAAAAEhpaX4MlCJFiig8PFxPnjwxpoWHh0uSLFw5AwAAAAAAAABSWJoP0qtUqaKXX35ZX331lYKCguTv768JEyborbfeMh4+CgAAAAAAAABASknzQbqTk5MWLVokBwcH1a9fX/Xr11e+fPk0cuRIWxcNAAAAAAAAAJABpPkx0iUpb968mjBhgq2LAQAAAAAAAADIgNJ8j3QAAAAAAAAAAGyJIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATDjaugAAAAAAMoAh7yq3rcvwHKAOkwf1mHTUYdJRh0lHHSYddZh01GEyGLLK1iWIF3qkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAMdq7d6/ee+89lS1bVlWrVtWwYcMUHBwsSRo8eLBKliwpT09P42fp0qU2LjEAAACQMgjSAQAAAETj7++vTz/9VO+//74OHTqkVatW6cCBA5o5c6Yk6fjx4xo2bJiOHj1q/LRu3drGpQYAAABShqOtCwAAAAAg7XFzc9OePXvk6uoqi8Wie/fuKSQkRG5ubgoNDdXZs2dVsmRJWxcTAAAAzwE7O1uXIG4E6QAAAABi5OrqKkmqUaOGbt68qfLly6t58+by8/NTWFiYfvjhBx0+fFjZsmVTixYt1LFjR9nbc9MrAAAAEiZXrmy2LkKcCNIBAAAAmNq6davu37+vPn36qEePHmrXrp28vLzk7e2t77//XqdPn1a3bt1kb2+vjh072rq4AAAASGfu3n0oi8U2+86dO34hPt1FAAAAAJjKnDmz8ubNKx8fH+3evVslS5bUwoUL5eXlJScnJ5UuXVqffPKJNm7caOuiAgAAIB2yWGz3E18E6QAAAACiOXLkiN5++22FhoYa00JDQ+Xk5KQ///xTP//8s9XyoaGhypw5c2oXEwAAAEgVBOkAAAAAonF3d1dwcLDGjx+v0NBQXbt2TWPGjFHLli3l5OSkUaNGae/evbJYLDp69KgWLlyo1q1b27rYAAAAQIpgjHQAAAAA0bi4uGj27NkaOXKkqlatqmzZsqlJkybq1q2bnJ2dNWDAAA0ZMkQ3b95U7ty51b17dzVt2tTWxQYAAABSBEE6AAAAgBgVKVJEc+fOjXFemzZt1KZNm1QuEQAAAGAbDO0CAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACbSRZC+ceNGFS9eXJ6ensaPj4+PrYsFAAAAAAAAAMgAHG1dgPg4fvy4mjZtqlGjRtm6KAAAAAAAAACADCbdBOkNGjSI9/J2dilYGAAAkKbwfx8AAAAAkNLSfJAeHh6ukydPKkuWLJo9e7aePn2qGjVqqE+fPsqePXu05d3cXOTgkC5GrAEAAMkgd+5sti4CAAAAAOA5l+aDdH9/fxUvXlz169fXDz/8oICAAPXr108+Pj6aOXNmDMsH0TMNAIAM5M6dh7YuAhAvfOkDAAAApF9pPkjPnTu3fH19jddZsmSRj4+PWrVqpcDAQLm6ukZbx2JJzRICAABb4v8+AAAAACClpfkxUPz8/DRu3DhZolwlh4aGyt7eXs7OzjYsGQAAAAAAAAAgI0jzQXqOHDnk6+ur2bNnKywsTNevX9fYsWP17rvvEqQDAAAAAAAAAFJcmg/S8+XLpxkzZujXX3+Vl5eXWrRooVKlSmnQoEG2LhoAAAAAAAAAIANI82OkS5KXl5d+/vlnWxcDAAAAAAAAAJABpfke6QAAAAAAAAAA2BJBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMOFo6wIAAAAAyACGrNKdOw9lsdi6IOmTnZ2UO3c26jCJqMekow6TjjpMOuow6ajDpKMOk4ednZTb1oWIJ3qkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADARLoJ0p8+fSpvb2/179/f1kUBAAAAAAAAAGQg6SZInzJlig4dOmTrYgAAAAAAAAAAMph0EaTv3btXW7duVb169WxdFAAAAAAAAABABuNo6wLE5e7duxo4cKCmTZum+fPnx2sdO7uULRMAAEg7+L8PAAAAAEhpaTpIDw8Pl4+Pj9q1a6dixYrFax03Nxc5OKSLjvYAACAZ5M6dzdZFAAAAAAA859J0kD5jxgw5OzvL29s73uv4+wfRMw0AgAzkzp2Hti4CEC986QMAAACkX2k6SF+zZo1u3bql8uXLS5KCg4MlSdu3bzd98KjFkirFAwAAaQD/9wEAAAAAKS1NB+mbN2+2et2/f39J0ujRo21RHAAAAAAAAABABsRg4gAAAAAAAAAAmEjTPdKfRU90AAAAAAAAAEBqo0c6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMCEo60LAAAAACADGPKuctu6DM8B6jB5UI9JRx0mHXWYdNRh0lGHSUcdJoMhq2xdgnihRzoAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJmwSpAcGBtpitwAAAAAAAAAAJFiKBuleXl4xTq9Zs2ZK7hYAAAAAAAAAgGTjmNwbvHTpkgYNGiSLxaLAwEB9/PHHVvMDAwP1wgsvJPduAQAAAJg4f/68XF1dlTdvXlsXBQAAAEh3kj1If+WVV1SvXj0FBAToyJEj0XqlOzs7q3bt2sm9WwAAAABRHDlyRN9++61Wr16tn3/+WUOGDJGjo6MmTpyot956y9bFAwAAANKVZA/SJenDDz+UJP3vf/9Ts2bNUmIXAAAAAEyMHz9eNWvWlMVi0YwZMzR69GjlyJFD48ePJ0gHAAAAEihFgvRIzZo107Fjx/Tvv//KYrFEmwcAAAAgZVy4cEGLFy/WhQsXdOfOHTVs2FDOzs7q1auXrYsGAAAApDspGqR///33mjVrlvLkySNHx//blZ2dHUE6AAAAkIIcHBwUFBSk33//XR4eHnJ2dta1a9fk6upq66IBAAAA6U6KBulr1qzR9OnTVaNGjZTcDQAAAIBnvPXWW/roo4907do1ff311zp37py6deumxo0b27poAAAAQLqTokH6o0eP9Oabb6bkLgAAAADE4JtvvtGaNWuUOXNmNWzYUBcvXlSbNm308ccf27poAAAAQLpjn5Ibr1mzptatW5eSuwAAAAAQAwcHBzVt2lQNGzaUJF26dEnlypWTg4ODjUsGAAAApD8p2iM9JCRE/fv31/Tp05U7d26reQsXLkzJXQMAAAAZ2m+//aavv/5ae/bs0bRp0zR9+nTZ2dlp4MCBatWqla2LBwAAAKQrKRqkFy1aVEWLFk3JXQAAAACIwY8//qiePXsqPDxcixcv1uTJk5UrVy716tWLIB0AAABIoBQN0j///POU3DwAAACAWFy+fFmtWrXSqVOn9PjxY1WtWlWOjo66c+eOrYsGAAAApDspGqQPGDAg1nmjRo1KyV0DAAAAGVqWLFl09+5d/fbbbypXrpwcHR3l5+ennDlzJnhbT58+Vdu2bVWgQAGNHj1akrRlyxZNmzZNV65cUY4cOdS8eXN17dpV9vYp+hgmAAAAwCZStZUbEBCgTZs2KWvWrKm5WwAAACDDadGihZo1a6ZZs2bJ29tbJ06cUNu2bdWmTZsEb2vKlCk6dOiQ8frEiRPq27evevbsqUOHDmnWrFlauXKl5s+fn4xHAAAAAKQdKdojPaZe53v27NGSJUtScrcAAABAhte9e3d5eXkpU6ZM8vDw0H///advv/1W9erVS9B29u7dq61bt1qtd+3aNbVp00a1atWSJBUuXFh169bVwYMH1b59+2Q9DgAAACAtSPX7LqtUqaJ9+/al9m4BAACADKdixYry8PCQJOXPn1+1a9fWqVOn4r3+3bt3NXDgQI0fP15ZsmQxptevX99qGMfg4GDt3LlTJUqUSLayAwAAIOOws7PdT3ylaI/0Z4WFhWn9+vVyc3NLzd0CAAAAGc7OnTs1dOhQ3bx5UxaLxZju6Oio48ePx7l+eHi4fHx81K5dOxUrVizW5QIDA/XFF18oc+bMatu2bXIUHQAAABlMrlzZbF2EOKVokF6sWDHZPRPrOzg4aODAgSm5WwAAACDDGzdunOrVq6cXXnhBZ86cUePGjTV16lS1bNkyXuvPmDFDzs7O8vb2jnWZCxcuqEePHsqVK5cWLlwoV1fX5Co+AAAAMpC7dx8qSt+PVJU7d/xC/BQN0hcuXGj12t7eXq+88ory5MmTkrsFAAAAMrwrV67Ix8dHV69e1b59+1SvXj299tpr6tWrl2k4HmnNmjW6deuWypcvLyli+BZJ2r59uw4dOqRdu3bpyy+/VKtWrdS7d285Oqbqza4AAAB4jlgsslmQHl8p2tr18vJSeHi4Tpw4oatXr+rFF19Urly5UnKXAAAAACS5ubnJ3t5eL730ks6fPy9JKlKkiG7cuBGv9Tdv3mz1un///pKk0aNH66+//lK3bt00ZMiQePdwBwAAANKzFA3Sb9++rS5dusjPz085cuRQQECAChUqpLlz5ypfvnwpuWsAAAAgQ3N3d9ekSZPUrVs35cqVS7t27VLmzJmVKVOmJG97+vTpCgsL04gRIzRixAhjerly5TR79uwkbx8AAABIa1I0SB8zZowKFSqkhQsXysXFRQ8fPtSQIUM0atQoTZo0KSV3DQAAAGRoPj4+6tGjh1q1aqUePXqoa9euCg8PV9++fRO1vdGjRxu/T58+PbmKCQAAAKQLKRqk79u3T5s3b5aLi4skKVu2bBoyZIjq1KmToO3s3btX33//vc6fP68sWbLo7bfflo+PjzJnzpwSxQYAAADSvcKFC2vDhg2SpAIFCmjHjh0KCgrSq6++auOSAQAAAOlPigbp4eHhsrOzs5pmZ2cnJyeneG/D399fn376qYYMGaJmzZrpzp076tChg2bOnKkePXokd5EBAACAdO3gwYOm8+/cuaMKFSqkUmkAAACA50OKBukVK1bUkCFDNHToUGXNmlVBQUEaMmSIvLy84r0NNzc37dmzR66urrJYLLp3755CQkLk5uaWgiUHAAAA0idvb2/T+XZ2djp9+nQqlQYAAAB4PqRokO7j46N27drJy8tLOXLk0L1791S4cGHNnDkzQdtxdXWVJNWoUUM3b95U+fLl1bx581iXf6YTPAAAeI7xfx+w5ufnp/DwcF25ckWvvPKKMX3Dhg2qX7++HB1T9BIAAAAAeC6lWCvaYrEoLCxMGzZs0KFDh3T37l1du3ZNHTp0kIODQ6K2uXXrVt2/f199+vRRjx49NHv27GjLuLm5yMHBPqnFBwAA6UTu3NlsXQQgTXn06JHat2+v3Llza8qUKZKku3fvasCAAfL19dXs2bOVNWtWG5cSAAAASF9SJEh/tvFeqVIl3b17V7Vq1dLOnTsT3XjPnDmzMmfOLB8fH7333nu6f/++smfPbrWMv38QPdMAAMhA7tx5aOsiAPGSWl/6/Pjjj3JyctLQoUONably5dKOHTv02WefacaMGerVq1eqlAUAAAB4XqRI122zxntYWJhmzJgR720dOXJEb7/9tkJDQ41poaGhcnJyUpYsWWJcx2Lhh5+0/QMASD62/kznh5/4/qSWLVu2aPjw4cqVK5fV9Fy5cmno0KHavHlz6hUGAAAAeE6kSJCenI13d3d3BQcHa/z48QoNDdW1a9c0ZswYtWzZUs7OzslddAAAACBdu3v3rtXY6FG98cYbun37diqXCAAAAEj/UiRIT87Gu4uLi2bPnq1//vlHVatWlbe3t6pUqaKvvvoquYoLAAAAPDdcXV0VEBAQ47x79+7FelcnAAAAgNilyBjpkY33nDlzRpuXmMZ7kSJFNHfu3OQqHgAAAPDcqly5snx9ffX5559Hm7dkyRJ5eHikfqEAAACAdC5FgnQa7wAAAIBtfPrpp2revLkCAgLUsGFD5cmTR7du3dKmTZv0yy+/aPHixbYuIgAAAJDupEiQTuMdAAAAsI1XX31Vc+bM0eDBg+Xr6ys7OztZLBYVLVpUs2bNUsmSJW1dRAAAACDdSZEgncY7AAAAYDtly5bVunXrdOXKFfn7+ytPnjx66aWXbF0sAAAAIN1KkSBdovEOAAAA2NrLL7+sl19+2dbFAAAAANK9FAvSI9F4BwAAAAAAAACkZ/a2LgAAAAAAAAAAAGkZQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABgwtHWBQAAAACQAQxZpTt3HspisXVB0ic7Oyl37mzUYRJRj0lHHSYddZh01GHSUYdJRx0mDzs7KbetCxFP9EgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATKSLIN3Pz0/t2rWTl5eXqlatqr59+8rf39/WxQIAAAAAAAAAZABpPkgPDg5Wx44d5enpqT/++EPr16/XvXv39NVXX9m6aAAAAAAAAACADMDR1gWIy/Xr11WsWDF169ZNDg4OcnZ2VuvWrdW3b99Y17GzS8UCAgAAm+L/PgAAAAAgpaX5IP21117T7NmzraZt2bJFJUqUiHF5NzcXOTik+Y72AAAgmeTOnc3WRQAAAAAAPOfSfJAelcVi0cSJE7Vjxw4tXrw4xmX8/YPomQYAQAZy585DWxcBiBe+9AEAAADSr3QTpAcGBmrAgAE6efKkFi9eLHd391iXtVhSsWAAAMCm+L8PAAAAAEhp6WIMlMuXL6tFixYKDAzUihUrTEN0AAAAAAAAAACSU5oP0u/fv69PPvlEZcuW1Zw5c+Tm5mbrIgEAAAAAAAAAMpA0P7TLypUrdf36dW3atEmbN2+2mnf06FEblQoAAAAAAAAAkFGk+SC9Xbt2ateuna2LAQAAAAAAAADIoNL80C4AAAAAAAAAANgSQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYMLR1gUAAAAAkAEMeVe5bV2G5wB1mDyox6SjDpOOOkw66jDpqMOkow6TwZBVti5BvNAjHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAIly/vx5dejQQeXLl1fNmjX1448/Kjw83NbFAgAAAJIdQToAAACABAsKClLHjh2VP39+/f777/L19dXGjRs1bdo0WxcNAAAASHYE6QAAAAAS7PDhw7p7964GDRqkrFmzqkCBAvrss8/0008/yWKx2Lp4AAAAQLJytHUBAAAAAKQ/4eHhcnJykpOTkzHNzs5Od+7c0YMHD5Q9e3Yblg4AAADpiZ2drUsQt3QVpPv7+6t169YaPny4KlasaOviAAAAABlW2bJllTlzZo0fP17dunWTv7+/5syZI0kKDg4mSAcAAEC85cqVzdZFiFO6CdIPHz6s/v376/Lly7YuCgAAAJDhvfDCC5o1a5ZGjRqlmjVrqmDBgmrWrJmOHz+uF154wdbFAwAAQDpy9+5D2Wp0wNy54xfip4sgfdWqVfrhhx/k4+OjXr16xbl8ergVAAAAJA/+7wO2ERoaqrCwMC1cuFB2//8PccmSJSpSpIiyZMli49IBAAAgPbFYZLMgPb7SRZBerVo1NWnSRI6OjnEG6W5uLnJw4BmqAABkFPHtPQAg+XXo0EF9+/ZVy5YtdfLkSU2fPl2ff/65rYsFAAAAJLt0EaTnyZMn3sv6+wfRMw0AgAzkzp2Hti4CEC/P25c+zs7OmjZtmkaNGqWRI0cqV65c6tSpk1q1amXrogEAAADJLl0E6QmV1m8DAAAAyYf/+4DtVKhQQStXrrR1MQAAAIAUxxgoAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACbS3RjpZ86csXURAAAAAAAAAAAZCD3SAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAw4WjrAgAAAADIAIas0p07D2Wx2Log6ZOdnZQ7dzbqMImox6SjDpOOOkw66jDpqMOkow6Th52dlNvWhYgneqQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADCRLoL0u3fvqmvXripfvrwqVqyoESNGKCwszNbFAgAAAAAAAABkAOkiSO/Zs6eyZs2q3bt3a8WKFdq7d6/mz59v62IBAAAAAAAAADKANB+kX7p0SQcOHJCPj4+yZMmil19+WV27dpWvr6+tiwYAAAAAAAAAyAAcbV2AuPzzzz/KkSOH8ubNa0wrXLiwrl+/rgcPHuiFF16Ito6dXWqWEAAA2BL/9wEAAAAAKS3NB+lBQUHKkiWL1bTI148ePYoWpOfJky3VygYk1pZvGtm6CAAAAKkud27a6klFHSYP6jHpqMOkow6TjjpMOuow6ajD5JEe6jHND+2SNWtWPX782Gpa5GsXFxdbFAkAAAAAAAAAkIGk+SD99ddf171793Tnzh1j2vnz55UvXz5ly5b2v6kAAAAAAAAAAKRvaT5IL1SokMqVK6eRI0cqMDBQV65c0bRp09SyZUtbFw0AAAAAAAAAkAHYWSwWi60LEZc7d+7o22+/1f79+2Vvb69mzZqpT58+cnBwsHXRAAAAAAAAAADPuXQRpAMAAAAAAAAAYCtpfmgXAAAAAGnP3bt31bVrV5UvX14VK1bUiBEjFBYWFuOyu3btUpMmTeTh4aEGDRpox44dVvNnzZqlN998Ux4eHvL29taFCxdS4xBsLiF1+NNPP6l+/fry9PRU/fr15evra8wLDw+Xp6enPDw85Onpafw8evQotQ7FphJSjx07dlSpUqWs6un333835nMumtdhx44drerO09NT7u7uGjRokCTORUny9/dX3bp1tX///liX4TPRXHzqkM9Ec/GpQz4PzcVVh3wexs7Pz0/t2rWTl5eXqlatqr59+8rf3z/GZdPd56EFAAAAABLoo48+svTu3dvy6NEjy+XLly2NGjWyzJo1K9py//77r6VUqVKWbdu2WZ48eWLZsGGDpXTp0pYbN25YLBaLZeXKlZbq1atbzp49awkODraMGjXK0qhRI0t4eHhqH1Kqi28dbtu2zVK+fHnL0aNHLeHh4ZYjR45Yypcvb9m8ebPFYrFYzpw5YylRooQlJCQktQ8hTYhvPVosFkvFihUt+/fvj3Ee52L86jCq5cuXW2rUqGG5efOmxWLhXDx06JDlrbfeshQtWtSyb9++GJfhM9FcfOqQz0Rz8alDi4XPQzPxrcOo+DyM8PjxY0vVqlUtkyZNsoSEhFj8/f0tnTp1snz66afRlk2Pn4f0SAcAAACQIJcuXdKBAwfk4+OjLFmy6OWXX1bXrl2tegRGWrVqlcqXL6+33npLjo6OatiwoSpUqKClS5dKkpYtW6YPPvhAr7/+ujJlyqTevXvr+vXrpr3ongcJqcObN2+qU6dO8vDwkJ2dnTw9PVWxYkUdPHhQknT8+HG5u7vL2dk5tQ/D5hJSj1euXNH9+/dVvHjxGLfFuRh3HUZ14cIFDRs2TOPGjdOLL74oKWOfi6tWrVKfPn3Uq1evOJfjMzFm8a1DPhNjF9865PMwdvGtw6j4PPw/169fV7FixdStWzc5OzsrZ86cat26tfH3GVV6/DwkSAcA6ODBg3H+AAAQ6Z9//lGOHDmUN29eY1rhwoV1/fp1PXjwwGrZc+fOqWjRolbTihQpIj8/vxjnOzk5qVChQsb851VC6vDDDz9U586djdd3797VwYMHVbJkSUkRF+shISFq0aKFKlWqpA8//FBHjhxJnQOxsYTU4/Hjx+Xi4qJevXqpUqVKaty4sVasWGHM51yMuw6jGjp0qJo1a6by5csb0zLyuVitWjVt27ZNDRs2NF2Oz8TYxbcO+UyMXXzrkM/D2MW3DqPi8/D/vPbaa5o9e7YcHByMaVu2bFGJEiWiLZsePw8dbbZnAECaMXDgQF25ckWWWJ4/bWdnp9OnT6dyqQAAaVVQUJCyZMliNS3y9aNHj/TCCy+YLps5c2ZjjNC45j+vElKHUd2+fVuffvqpSpYsqcaNG0uKqK/SpUvriy++UPbs2eXr66sOHTpo7dq1evnll1P2QGwsIfUYGhoqDw8P9erVS6+//rr279+v7t27y8XFRQ0aNOBcjCKuc/HQoUP6+++/NW7cOKvpGflczJMnT7yW4zMxdvGtw6j4TLQW3zrk8zB2CT0P+TyMncVi0cSJE7Vjxw4tXrw42vz0+HlIkA4A0M8//6w2bdqoV69eatCgga2LAwBI47JmzarHjx9bTYt87eLiYjU9S5YsCg4OtpoWHBxsLBfX/OdVQuow0l9//aUvvvhC5cuX16hRo+ToGHE5179/f6vlOnTooJUrV2rXrl366KOPUqD0aUdC6rFZs2Zq1qyZ8bpatWpq1qyZNm3apAYNGnAuRhHXubh06VI1aNAgWuCUkc/F+OIzMfnwmZh4fB4mHz4PYxYYGKgBAwbo5MmTWrx4sdzd3aMtkx4/DxnaBQAgNzc3jRo1SmPHjlV4eLitiwMASONef/113bt3T3fu3DGmnT9/Xvny5VO2bNmsli1atKj++ecfq2nnzp3T66+/bmwr6vwnT57o4sWL0W71fd4kpA4lacWKFWrbtq0++eQTjR8/3mrM1QkTJujUqVNWy4eGhipTpkwpdwBpRELqccWKFdq0aZPVtKj1xLkYv3MxLCxMv/76q955551o8zLyuRhffCYmDz4Tk4bPw+TB52HMLl++rBYtWigwMFArVqyIMUSX0ufnIUE6AECSVK5cOfXo0UMBAQG2LgoAII0rVKiQypUrp5EjRyowMFBXrlzRtGnT1LJly2jLvvPOOzpw4IA2btyosLAwbdy4UQcOHFDTpk0lSS1atNDixYvl5+enkJAQjR8/Xrlz57YaZ/R5lJA63LJli4YMGaLJkyerffv20eafPXtWI0aM0O3btxUaGqopU6YoMDBQdevWTY1DsamE1GNgYKCGDRumU6dOKTw8XDt37tT69evVunVrSZyL8alDSTpz5oxCQkJUtmzZaPMy8rkYX3wmJh2fiUnH52Hy4PMwuvv37+uTTz5R2bJlNWfOHLm5ucW6bLr8PLQAAAAAQALdvn3b0r17d4uXl5elUqVKltGjR1vCwsIsFovF4uHhYVmzZo2x7O+//2555513LB4eHpZGjRpZdu7cacwLDw+3zJkzx1K7dm2Lh4eHxdvb23LhwoVUPx5biG8dNm7c2FKsWDGLh4eH1c8333xjsVgsloCAAEv//v0tlStXNurw9OnTNjuu1BbfegwPD7dMnTrVUqtWLUvp0qUtjRo1smzatMnYDudi/P6eN23aZKlcuXKM28no52KkokWLWvbt22e85jMx4czqkM/E+DGrQz4P4yeuv2U+D6ObO3eupWjRopYyZcpE+xu1WNL/56GdxRLLk+UAAAAAAAAAAABDuwAAAAAAAAAAYIYgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHgOeYu7u79u/fn6h1vb29NXny5EStu3//frm7uydqXQAAAAAAgLSGIB0AAAAAAAAAABME6QCQQYWGhmrMmDFq0KCBPD09VblyZQ0bNkwWi8VY5vLly/L29laFChXUpk0bHTt2zJh3584d9enTR1WrVlW1atU0aNAgBQYG2uJQAAAAAAAAUhRBOgBkUAsWLNDu3bu1YMECHT16VNOmTdPPP/+sffv2Gcv8+uuv6tGjh/bs2aMaNWqoU6dOevDggcLDw9W1a1fZ29try5YtWrdunW7duqVBgwbZ8IgAAAAAxMfFixdtXQQASHcI0gEgg2rVqpXmz5+vPHny6NatWwoODpaLi4tu3rxpLNOyZUtVqFBBTk5O6tKlizJlyqRdu3bpxIkTOnnypAYPHixXV1flzJlT/fr104YNGxQQEGDDowIAAADSvn///Vf9+vXTm2++KU9PT7311lsaN26cgoKCUnzfvr6++uabb1J8PwDwvHG0dQEAALbx+PFjffvttzp48KDy5cun4sWLy2KxKDw83Fjmf//7n/G7nZ2d8uXLp5s3b8rBwUFPnz5VjRo1rLbp7OysK1eupNoxAAAAAOnNkSNH1L59e7Vv316rV6+Wm5ub/v33Xw0aNEjt27fXkiVL5ODgkGL79/f3T7FtA8DzjCAdADKor7/+WtmzZ9cff/yhTJkyKTw8XBUqVLBa5tatW8bv4eHhun79ugoUKKC8efMqc+bM2r9/v9HIDw0N1ZUrV/TKK6/o8OHDqXosAAAAQHoxaNAgNWvWTD169DCmvfrqq5owYYIGDRqkK1euyMnJSWPHjtX+/ftlb2+vSpUqqV+/fnrxxRe1f/9+ffzxxzpz5oyxfv/+/SVJo0eP1uTJk/XPP//I2dlZO3fuVNasWdW0aVP17t1bq1at0owZM/T06VOVL19ehw4dSvXjB4D0iqFdAOA55+/vrxs3blj9hIWFKTAwUJkyZZK9vb0CAwP13XffKTAwUE+ePDHWXbFihf7++2+FhoZq8uTJcnR0VI0aNVS6dGm98sorGj16tIKCghQcHKyRI0eqbdu2evr0qQ2PFgAAAEi7Ll++rH/++UeNGzeONi937tyaNm2aChQooPbt28vBwUFbt27Vpk2bJEldunRRWFhYvPazdetWVatWTfv379ewYcM0a9Ys/fXXX3r33Xf16aefEqIDQCLQIx0AnnM9e/aMNm3jxo36+uuvNWjQIHl5ecnFxUU1a9ZU9erVdfbsWWO5evXqafDgwbp8+bJKliypOXPmKGvWrJKkGTNmaMyYMapXr55CQkJUunRpzZs3T5kyZUqtQwMAAADSlchhVXLnzh3rMocOHdKVK1f0yy+/yNXVVZI0dOhQeXl56cSJE/HaT6FChdSsWTNJUo0aNZQnTx5dvHhRHh4eSSo/AGRkBOkA8ByLertnTFauXBnrvEWLFpmumy9fPk2YMCHGeRUrVoxz3wAAAEBGkydPHknS7du3VahQoWjz79y5o7t37ypnzpxGiC5Jrq6uypEjh65du2Yawj+7n0hOTk5Wz0ICACQcQ7sAAAAAAACkggIFCqho0aLauHFjtHl3795VrVq1dO3aNQUEBCgwMNCY9/DhQwUEBChPnjxWzyiKFBAQkPKFB4AMjiAdAAAAAAAglXzzzTf65ZdfNGXKFAUEBMhisej06dPq0qWLSpQoofbt26tIkSIaPHiwHj58qIcPH2rIkCEqWLCgypYtq4IFC8rR0VEbNmyQJO3Zs0f79u2L9/4zZcqkwMBAWSyWlDpEAHguEaQDAAAAAACkEi8vLy1evFinTp1So0aNVLZsWfXo0UOVKlXS7Nmz5eTkpBkzZigsLEz169dXrVq19OTJE82bN0+Ojo568cUX9dVXX2natGkqW7asFi9erObNm8d7/7Vq1dK9e/dUrlw5PXjwIAWPFACeL3YWvoIEAAAAAAAAACBW9EgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMEGQDgAAAAAAAACACYJ0AAAAAAAAAABMEKQDAAAAAAAAAGCCIB0AAAAAAAAAABME6QAAAAAAAAAAmCBIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADBBkA4AAAAAAAAAgAmCdAAAAAAAAAAATBCkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOpCBNGnSRO7u7nrjjTcUGBhoNe+7776Tu7u73N3dVbx4cT18+NBq/sCBA435x48fT7UyR93v1atXU22/CTF58mSjjIcOHUrUNiLXb9u2bfIWLpVcu3ZNQUFBxuurV68axzRw4MBEb7d27drGdqKen+XLl9d7772nuXPnKiQkJNb16tatm+h9S5K/v7/u3LkT7+VXrlxplHPNmjXG9NR6f8+ePWv1OjnOTQAAkD70798/Wrsptp+VK1faurjat2+faTvl8uXLpscQH1euXNGgQYNUt25dlSlTRqVLl1bdunX19ddf68KFCzGuEx4ernPnziXp2OIS0z6ivn83btxI0f3H140bNzR69Gg1bNhQnp6eKlOmjBo2bKgxY8bo5s2b0ZZP79c0sXm2jQ0g4yJIBzKQ8uXLS4pouB07dsxq3t69e43fnz59Gq0x+/fff0uSsmbNquLFi6dwSZFe3L9/X2PGjNHbb7+tgICAVNnn06dP9fDhQx07dkxjxozRhx9+GO2LoaQKDg7W9OnTVbduXZ0/fz5Zt50Sjh07Jm9vbw0bNszWRQEAAIjT7du3NXjwYNNlzpw5k6R9HD16VE2aNNHSpUt1+fJlBQcHKyQkRJcvX9by5cvVrFkz7d+/32qdP//8U82bN9fs2bOTtG8zqbGP5LB9+3Y1aNBA8+bN0/nz5/Xo0SMFBwfr/Pnzmjt3rho3bqzDhw/bupgpijY2gGc52roAAFJP+fLltWTJEknSX3/9pSpVqkiSAgICdPr0aatlDxw4oFq1akmSAgMDjTCxbNmycnBwSMVSIy0bO3asli9fnuL7KVCggJYsWSKLxWJcAM2bN0979uzR8ePHNXToUI0dO9ZYfunSpXr69Gmiz9V58+Zp4sSJCV6vQYMGxt9V9uzZE7XvxHj//fcVFhYmLy8vq+nt2rXTe++9J0lyc3NLtfIAAIDUN2DAAPXs2dN4PW/ePM2fP1+SNGXKFJUqVcqYl5rtlGcdO3ZMffr00aVLl0yXiwzSc+bMqdWrVyd4P4MHD9bjx4/l4uKi/v37q1y5cgoPD9fmzZs1ZcoUhYSE6JtvvtHWrVslSTdv3lT79u0lScWKFUvw/uLDbB9R3788efKkyP7j6++//1bPnj315MkT5ciRQz179lSlSpX08OFD+fr6avXq1Xrw4IG6d++urVu3ytXV1ablTSmxtbEBZFwE6UAGEtkjXfq/HuZSRG90i8UiSXJ1dVVgYKBV74zjx48rPDw82jaAyPMmpTk4OChfvnzG60KFCqly5cpq2bKl/Pz8tH79enXr1k2FChWSlPSLj8QeV5YsWZQlS5Yk7TsxYiuvq6vrc3thAwAArGXPnt0qII/aBsiZM6dVW8pWfHx8tH79eoWHh8vOzs60zRUZpL/88ssJLvu9e/eM9atXr65WrVoZ815//XUdP35cu3bt0qVLl3T16lX973//S5V2rdk+nn3/bGnUqFF68uSJHB0dNWfOHJUsWdKYV7p0aYWEhGjTpk3y9/fXjh071KRJExuWNuWk1rUOgPSDoV2ADCRv3rz63//+Jyl6kC5JL7zwglq2bClJ8vPzM8ZJ/+uvv4xlowbpoaGhmjNnjt599115enrK09NTrVu31ooVK6I1OiLHrO7Ro4dmzpwpLy8veXh4aOrUqca2fvjhB9WpU0elSpVSkyZNtHnz5hiPI+o41GfPntX333+vN998U2XKlJG3t7fOnj2roKAgjRo1SlWrVpWHh4fef/99HT161Go74eHhWrBggd59911VqFBBJUuWVPXq1fXll19aDecRdbzv2bNnq0+fPipdurQqVqyoP//8M8Yynj9/XhUrVpS7u7s8PT2t6js5hISEaMqUKapfv75KliypKlWqqHfv3vr3339jrSs/Pz/Nnz/fWKd+/fpGL6Worl69qi+//FJeXl7y9PRUp06ddOHCBXl7e8vd3V3e3t6SJG9vb61YscJYr06dOrGOV7l37161bt1apUuXVvXq1TV69GgFBwcnqQ6cnJzUunVrSRHv5Y4dO4x5sY2Rvnr1arVp00blypVT8eLFVbFiRXXo0MHqttT+/ftr0qRJxuuPP/7YGKM/rnMhtjHSn62L9957T6VKlVL16tU1cuTIaEPTxDa+5LNjnkeW5+nTp5Ii7iRxd3dX//79Y1w+qosXL+qbb75RrVq1VLJkSVWtWlW9evWSn5+f1XJRj3nx4sXatWuX8V5WrVpV3377rdX4+AAAIP3YvHmz2rZtq4oVK6pUqVJq2LChJk2aFK1tErVNcfPmTQ0fPlxVq1ZVmTJl9NFHH8X7WSw7duxQeHi46tevr48//th02ahBelhYmPz9/Y3OPXFxdHSUvX1E3PHbb79p7ty58vf3N+ZPmjRJe/fu1d69e5U/f37t379fNWrUMOavWrVK7u7umjx5sjFt586d+uSTT1SlShWVLFlSFStWVLt27bRr1y6rfZtd95jtI6Yx0hPTDnv06JG+++471axZU6VKlVLz5s21c+dOq/fQzMWLF43rpurVq1uF6JF69uypqVOnau/evbGG6KdOnVK7du3k4eGhSpUqaeDAgdGGgrx3755Gjx6tevXqycPDQx4eHqpXr55GjRqlBw8eGMtFbWP/+uuvatOmjUqWLKmaNWvq3r17CXp/JOnChQvy8fFRtWrVVLJkSdWqVUs+Pj7GuPlxtbGliLsLBg4caGzjrbfe0pgxY6I9ayzyGqp58+ZatWqVqlWrptKlS+vrr7+WFHHd2LNnT1WrVk0lSpSQh4eHmjZtqtmzZxPkA2kQPdKBDKZ8+fK6evWqAgICdOnSJb3yyivas2ePJKlixYqqVq2a5s+fr6dPn+rgwYOqXbu2EQI7OzurTJkykiIaaN7e3jpx4oTV9v/66y/99ddf+v333zVhwoRoQ2vs3btXW7ZsMV6XLl1aFotFPXr0sApCz549qy+++EIvvvii6fH07t3b6uEvBw4cUPv27ZUvXz6rh6IeOXJEHTp00ObNm41tjhkzJlqQfOvWLW3YsEF79uzRli1bovUKmTFjhlWjrnTp0jpy5Ei0bXTq1En37t2Ts7Ozpk2bZtRbcggNDVX79u2tLlju3r2r9evXa9euXVq4cGGM49gPGzbMap2LFy9q1KhRypEjh5o1ayYp4qGh7733ntWFxu+//67jx48rW7ZsiSrvwYMHtWrVKqMheuvWLc2bN08hISFxjo0ZlxIlShi/nzp1ynTZBQsWaOTIkVbT7t27pz/++EMHDx7UggUL5OnpGe99x3QubNu2zXSdM2fOqGPHjgoLC5MUURcLFizQ0aNH5evrK2dn53jvPyn27t2rrl276tGjR8a0O3fuaOPGjdq2bZu+++47NWzYMNp6Gzdu1JEjR4xGfUhIiHx9ffX48WONGjUqVcoOAACSx5AhQ/TTTz9ZTTt//rymTZumzZs3a9GiRcqdO3e09Tp16mQ1fvnBgwfVtm1b/fjjj6pevbrpPsuXL69WrVqpdu3aViH1sx49eqQrV64Y2y9XrpyCg4OVPXt2vf/++/r888/l5OQU6/qurq6qWbOmfvvtN4WGhmrMmDEaO3as3njjDVWuXFl16tRR2bJlTcsa1fbt29W9e3erIP/evXvas2eP9u7dq0WLFqlChQpW68R03ZMU8WmHPXnyRB06dLC6Pjl58qQ+++wzq3azmaidqDw8PGJcplChQsadoDG5ePGiPvjgAz1+/FiS9PjxY61YsUK3b9/WzJkzJUU896hDhw7RricvXbqk+fPny8/PTwsWLIi27f79+xtt8Lx58ypHjhwJen+OHj2q9u3bW7WDr1+/rrVr12rXrl1avHixsmbNGnsFKeIhtu+//75u375tNW3u3LnavXu3fv7552h3hV66dElfffWVUcaSJUvq2rVrat26tVX4HhYWJj8/P/n5+enGjRtG4A4gbaBHOpDBlCtXzvj96NGjRi9bSapcubLKly9vNEoPHDggScaDSUuXLm0Efd99953R6GncuLFWrlypn3/+WVWrVpUkbdmyRXPmzIm2/wcPHujtt9/Wpk2bNGHCBFWpUkW//fabEaIXKlRIc+bM0Zo1a/Tuu+/q1q1bpsdz/fp1/fDDD1qzZo0RVt++fVtnz57VmDFjtHHjRmOs96CgIO3evVuS9PDhQ2OsxVq1amnDhg3auHGjESgHBARE68EeWf4+ffoY5X82XA4KClLnzp117do1OTo6auLEiapcubLpMSTUwoULjUC8c+fO2rhxo+bPn6/XXntNDx8+jLWxdezYMQ0bNkwbN25Uu3btjOm//PKL8fv3339vhOjNmjXTmjVrNH/+fOXOnVuXL1+22t6kSZPUuHFj4/XSpUtj7PFx6dIlffLJJ9q4caPGjx9vnEMrV640wvXEeuGFF4zf79+/b7psZO/5YsWKaenSpdq+fbt++OEHubi4yN7eXhs3bpQUMT5lhw4djPUmTpyoXbt2KX/+/Fbbi+tciIm/v7+qV6+ulStXytfX17igOXbsWKLGms+fP7927dplfGHl4eGhXbt2acCAAbGuExQUpN69e+vRo0fKmjWrBg0aZLw3bm5uevLkifr37298LkR1+PBheXt7a+PGjRozZoyx33Xr1unJkycJLj8AALCNjRs3GiF6iRIlNH/+fK1du9a4G+7ChQvq169fjOteuXJFI0aM0MaNG9W7d2/Z2dnpyZMnGjx4cJxtu+nTp6t27dpxlu+ff/4xAsdbt24ZdzLev39f06dPV+/evePcxvDhw/XGG28Yr8PDw3Xy5EnNnj1b77//vlq2bGn0QPb09LS60/Ltt9/Wrl27jDbz4sWLFR4erldeeUU///yztm3bpoEDB0qKGP7jt99+i7b/Z697KlasaLqPuMSnHbZy5UojRC9ZsqR8fX21atUqvfXWW1adjMzcuXPH+D2xz9j577//VK9ePa1bt04zZ85Ujhw5JEm7du3SzZs3JUVca0Z+IdOtWzdt27ZNK1asMNrH+/fvj/GuxydPnmjGjBlavXq1+vbtKyn+74/FYtFXX32lR48eydnZWUOHDtXmzZs1evRoOTk56f79+xo7dmycbexhw4bp9u3bypw5s8aMGaMtW7Zo3Lhxypo1q/755x9NmTIlWrkDAwNVvnx5rV+/XtOmTVODBg20ZcsWI0QfP368tm/frl9++UVeXl6yt7fX7t27o90dAsC26JEOZDBRg/S///5boaGhxuvKlSsrS5Ys8vT01IEDB3TgwAFduXJFd+/elfR/w7oEBQVp1apVkiKGoBg7dqxx6+SUKVNUr1493b59W4sWLVLnzp2jlWHAgAHKly+fXnvtNUmyCl+HDRtmPMxl+PDhOnDggK5duxbr8bRq1Ur169eXJDVt2tToPd+sWTMjFH/vvfeMoD7yWLJly6Z9+/bp6tWrypEjh7Jly6Z79+5Z9ayIvE0wqoIFC6pTp06SZJQ/qiFDhuj69euSIsaArFOnTqxlT6z169dLingA54cffihJevXVV+Xt7a2hQ4fq5MmTOnv2rIoWLWq1XqtWrYzxIfv27auff/5Zjx8/NhrLUYdHKVCggEaMGCFHx4h/E+PGjVPTpk2ttufm5qbMmTMbr3Pnzh3j+JVFixY1LsQKFy6s9evXa8eOHQoODtb9+/eT9BDMqLc7xnXhFtmAv337to4ePaoqVaqobt268vLyUo4cOWRnZycpYnzKqD1I3NzcYjyuuM6FmGTLlk3jxo0ztj927Fij5/fOnTuN9zO+nh073tnZOc4xRDdu3Gj8HfTo0cPYZ+HCheXk5KQePXooJCREy5Yt05dffmm1btGiRY2Lksj3cvfu3Xry5Inu378fY681AACQ9ixevFiSlClTJv3444/KmzevpIh2+qVLl7Rjxw798ccf+vfff/Xqq69ardu5c2djOMjChQvr1KlT2rRpk65duyY/P79493w2ExISIg8PD926dUsdO3ZUw4YNFRAQoD59+ujkyZPasmWL9u3bp0qVKsW6jVy5cmn58uXasGGD1qxZo4MHD1p98X/8+HG1a9dO69evV7Zs2ayesZMlSxarNtX8+fN19+5dhYWFKW/evAoJCVHhwoWN+bF16Hj2usdsH3GJTzvs119/NZb//vvv9corr0iKaMvXqVPHqgd1bKL26o7vUDrPypEjh0aMGCEnJycVLVpUTZo00aJFiyRFDImSN29eVa5cWUePHtXFixdVpEgR2dnZ6erVqypQoIBOnjwpi8WiBw8eyMXFxWrbjRo1Us2aNa2mxff9OX36tPHlSfPmzdWmTRtJEddST58+lZ2dnYoVK2baxn7w4IHROeutt94yzsEKFSqobt26WrNmjVavXm01DEykL774Qq+//rpef/11o54i7d+/Xzlz5pSHh4dmzJghe3t7q2stAGkDQTqQwRQuXFhubm7y9/fX33//bYxTF7WBV7lyZR04cECnT5/WH3/8YawbGaT/+++/Rq+QypUrGyG6JGXNmlUeHh7atm2bbt26JX9/f6ugNFu2bNEajFGD8qhDoDg6OqpEiRKmQXrUhn3URlbUsf+iTo8cUkOK6M1w8OBB7d69W8eOHYvWAzemhmNkoyc2kSG6FNEYenaM6+Rw8eJFSRH1FnWcxahOnjwZLUiP+tre3l7Zs2fX48ePjTrx9/c3en2UKlXKCNGliF7ckQ+iTahnyxG1F3lSezFHLU9cD2fy8fFR586ddffuXY0ePVpSxPlYvnx5NWrUSI0aNbI6l+MS17kQk8KFC1uF9JGvAwMD9d9//8W5fnKMkxh1DPRn75aIvKNEktUt25GefS9z5sxp/B71bwsAAKRtp0+flhTRFokM0SNVqVLF6Fxx5syZaEH6s0OieHp6atOmTZIixpZOjiDdy8tLS5cutZqWM2dO9e7dW+3bt5ck/fnnn6ZBuhTxTJ3IDjbBwcE6fPiwdu7cqV9++UVBQUG6ceOG1q1bpw8++CDOMp0+fVpbt27V0aNH9e+//1q1Y2O6bojpuicp4tMOixwOx83NzQjRpYgvTEqVKhVjz/lnRd1uZOeLZ1ksFqMTSkxeffVVq6F3ot65GbXe7t+/r127dhl3O0cdXlKKuaNMbG3w+Lw/kddRkqzuVpBkfDkUl4sXLxrbW79+vdHJKaqAgABdu3ZNBQoUsJr+7HvYuHFjbdiwQX/88YeWLVumZcuWycHBQcWKFVPt2rXVpk0bOqoAaQxDuwAZUGSv9DNnzhgPGo0aqEX+Hh4ernnz5kmK6PkaOX501IA1pgZU1LDv2fkxDX8RdZlnG6FxBZuZMmWKcTtZsmQxLeOjR4/UunVrDRgwQLt27VKFChU0bNgwDR061HR/8Rm+IzLE/+2336y+iEguz447H5NnG6GSovVoeHY7URu7MQW2Zo1lM8/uN+p7mtRgOGrYW6xYMdNlS5cure3bt2vEiBGqX7++cufOrYcPH2rHjh3q06ePevXqlaB9J2bM+Ji+OIj8e4rpXH/24iEkJCTB+3xW1Pfd7D2NaV5c5xAAAEgfItsfCW3LS7K6ozU+yyenqMG02YPrt2/frt69e6tt27bGMJWZM2dW1apVNXDgQP3www/GspE9lM0MGjRIHTp00PLly1WgQAF9+eWX8vX1NV0nsc8Xik182mGR7fmktLGjdmyKOl56VFu3blWdOnU0fPhw40sZs7LG1P7/559/1LBhQ40dO1bnzp1TkyZNNGHCBL3//vum5YupXhPz/iS2E0jUa2EzMV2PPTtuurOzs+bMmaMFCxbI29tbRYsWlcVi0cmTJzV58mQ1adLEtFMZgNRHkA5kQJE9y8PCwozhS6IG6aVLlzb+yV+6dElSxDf2kdP+97//GeNc79271yr8fvTokTG8Sr58+ax6NEgxNzwKFixo/B7Z0JUiQsf4juWXUJs2bTIeTjlixAiNHj1arVq1irNXc1wNp/bt22vJkiVGz4GRI0cme0/dyN4lr732ms6cOWP87NixQ5s2bdLJkyetxviOr+zZsxu9xU+cOGFV7pMnT0Z7Ar1kfbFki6fKr1mzxiiH2TA6YWFhOnPmjHbv3q2CBQvqhx9+0J9//qnt27cb5/7mzZuNMRvjc1zxbURHde7cOeMuECmi11Dk32DUv4PIi6Bnx4WMrdd6ZHnj8x5Evc018ou0SH/++afxe1xfTAAAgPQrsj1w7tw5o/0TKWr74Nleu1LEwz+jitpej9qeSYq5c+eqdevWqlOnjtVwi//884/x+7M95aMKCgrS+vXrtXfv3mgPVJWs23qR7f/Y2n9Xrlwxese3adNG06dPV/v27eMc2i+mtmJKt51ffvllSRE9oqP2vn78+HG8r6uKFi2q4sWLS4poGz77MNCnT59q3rx5unr1qhYtWmS1n4SYPXu2MeTKL7/8oq+++koNGzaM88uYZ+s1Ie9P1F76zx7X+PHj1aFDB40aNcro/BJTGzvqOd6mTRur67F169Zp165dOnPmjEqVKmW1fQcHh2gdZ27cuKE//vhDV65c0ddff61169bp4MGDxljs/v7+WrdunWl9AEhdDO0CZEBRx0mPFDVId3BwkJeXl9Wtf5HhuxTxTfrbb7+ttWvXys/PT/369VO7du0UGhqqyZMnG2PvffTRR/EqT7169YweAwMGDNCQIUOUN29ezZ49O8W+gY8aUG7evFnu7u66dOmSxo8fb0xPzIMw69SpI1dXV/Xo0UODBg3S+fPn5evrq08++SRe69+/f1979uyJcZ6Li4vKlCmjJk2a6OTJk7pw4YKGDx+u1q1bKyAgQMOGDdPZs2eVNWtWbdmyRS+++GKCy9+oUSP99NNPunbtmr7++mu1a9dOt2/f1vDhw2NcPuodAUePHtWdO3eMOxeS09OnT3Xjxg1JEaH4jRs39NNPPxkXcg0aNLAKiJ8VEhKijz76SA8ePJCbm5uGDRsmd3d33bx5Uw8ePJAU0VCO7NkT9biOHTumbNmymV6sxVdISIi6dOkiHx8fOTs7a+TIkca8t956y/g9b968unr1qvz8/Izblrdt26atW7fGuF1nZ2eFhYXp+vXrOn/+vMLDw2O97fXtt9/WmDFjFBQUpEmTJilz5syqUKGC/Pz8NGLECOP4I8fTBwAAz58WLVro6NGjCgkJUdeuXeXj4yM3NzetWrXKGNblzTffjDEYX7BggfLnzy8vLy/t3r3bGNalUKFCVsMrJoWbm5vRG7p3797y8fGRv7+/xo4dKyliqMDI58zEpG7dusqdO7fu3LmjlStXKlu2bHrnnXfk4uKikydPaty4ccay9erVkySjo5AUMXzHhQsXZG9vb9Xz/cCBAzp+/LjCw8M1adIkY3p8O87Eto+oz2lKikaNGmn79u2SIupt4MCBcnJy0tSpU+M1Pnqkr776Sm3btlVYWJg6duyo3r17y8vLS7dv39asWbN09OhRSREdLyLrL6GiXo+tWLFC9erV0969e7Vy5Upjenyux6JuJ67354033lChQoV08eJFrV+/XiVKlFC1atV04sQJzZ8/X6GhoQoLCzM6tcTWxq5Vq5Z27NihlStXqnjx4vLy8pKfn5/xINOSJUtqxYoVcX4pMGXKFC1fvlySdPnyZeMZX5HXPVLiOu8ASDn8RQIZUPHixZU1a1Y9evRIklSkSJFooWvlypWtgvQKFSpYzf/666/l5+ens2fPau3atVq7dq3V/Pr16xvjF8alUqVKevfdd7Vq1Spdu3bNeICjJJUoUUInT55M0PHFx5tvvqnx48crODhYmzdv1ubNm6Mtk5DG5rNatmypxYsX6+zZs5oyZYqaNGkSr4dqnjp1Su3atYtxXrFixbRmzRq9//77WrdunU6ePKlFixYZD+6J9NlnnyUqRI9cd9u2bbpz545WrVplPFT2pZdesjpnopYpko+Pj6TovZyTg9l48MWLF9e3335rur6Li4u++eYb9evXT/7+/urWrVu0Zd5//33jToKova/Gjx+v8ePHa/ny5Ul6MKoUcT4fP3482kNFK1asqCZNmhivGzdurOnTp+vp06dq37697OzsZLFY5OHhEeMttm+88YYOHz6sa9euqWHDhqpRo4ZmzpwZYxmyZ8+ucePGqWfPnnr06JEGDx5sNd/JyUljxozRSy+9lKRjBQAAaVfLli114MABrV27VidOnIjW6eO1117TqFGjYlw3Z86cGjJkiNU0JycnDR06NNmGdnnnnXe0YcMG/f777/rjjz+shku0t7fX4MGDrR7U+KysWbNq7Nix+uyzzxQcHKwFCxZowYIF0Zb74osvjPA/R44cyp8/v/777z/99ddfatCggT744AMNHDhQhQsX1vnz53Xu3LkYx9K+c+dOvI4rtn082x5LrLfffltLlizRwYMHdeLECWOYFCcnJ7388svGGOpxqVChgsaOHav+/fsrICBAX3/9dbRlChQooMmTJyd6qL969epp27Ztkv6vvf2s27dvW/Uij0mRIkXi/f7Y29tr5MiR6tChgx4/fhyts1C2bNmM3uBS7G1sHx8fHT16VPfu3dOgQYOstpE5c2b5+PjE62+he/fu2rdvn65cuaKZM2dGa7+/9NJLat68eZzbAZB6GNoFyICijncuRX/goBTxkKFIdnZ20XqxZ8+eXb/88ov69u2rEiVKKGvWrMqSJYvKlCmj4cOHa9KkSQlqVI0cOVJ9+vTRyy+/LCcnJxUrVkzff/+93nvvvUQcYdwKFSqk2bNnq1y5cnJxcVGOHDlUvnx5zZo1y+gREp+H8cTGwcHBaIQ9ePBAEydOTIZSR8icObMWLlyorl27qnDhwsqUKZOyZ8+u8uXL64cfflDnzp0Tve28efPqp59+Ut26deXq6ioXFxfVr19fvr6+Rg+aqD1pmjRpoubNmytPnjzKlCmTihYtajpeZXKwt7dXtmzZ5OHhoa+++kpLly6N1xiU77zzjnx9fVWvXj299NJLcnJykouLizw8PPTtt9/qm2++MZatVKmS2rdvr5deeknOzs7J1kuoYsWKmjt3rjw9PZUpUyblzZtXHTt21MyZM63+Xj7//HN99tlnyp8/v5ydnfXGG29ozJgx6tKlS4zbHTBggMqWLausWbMqe/bs0R4a9qzatWtrzZo1atWqlQoUKCAnJye5ubmpQYMGWr58uRo0aJAsxwsAANImOzs7jR07VhMnTlTVqlWVI0cOOTk56dVXX1XXrl21fPnyWB9yOHLkSLVr105ubm7KnDmzvLy8tGjRojgf/JkQ9vb2mjp1qgYMGKA33nhDWbNmVbZs2VStWjUtXLhQjRs3jnMbVapU0dq1a9WmTRsVKlRImTJlkrOzs/Lly6f69etr/vz56tq1q1WdfPvttypRooQyZcokNzc35cqVS46Ojpo1a5befvttubm5KWvWrHJ3d9eAAQOM0Pbw4cPGMCVmYttHcrG3t9eMGTP0ySefGO1zT09PzZ8/3xiuJWpb3kzDhg21YcMGffDBBypYsKCcnZ2VJUsWFStWTN27d9fatWuTNJTPO++8o2HDhqlIkSJGu7hu3bqaP3++EULH53osoe9PuXLltGLFCjVq1Ei5c+eWk5OTChQooKZNm2rZsmVWHYVia2MXLlxYK1asUPPmzZUvXz45OTkpT548ql+/vpYsWRLvv4W8efNq2bJl+vTTT1WkSBG5uLjIyclJBQsW1EcffZQsHXkAJC87iy0GtQUApEl//vmncYGRP39+41bC8PBweXh4KCQkRI0aNdL3339v45ICAAAgtUyePFlTpkyRJPn6+loN+4i04/Tp0/L391e+fPn00ksvKUuWLMa8Dh066I8//lCePHmsevgDAOKPoV0AAIZFixYZ42K+99576tSpk0JDQ7Vy5UqFhIRIUrQH5wAAAACwvb1792rMmDGSItrsw4cPV5YsWXT48GHt379fklSyZElbFhEA0jWCdACA4aOPPtKuXbsUHh6u5cuXGw+/iZQ/f37G6QMAAADSoCZNmmjmzJkKCAjQ8ePH1bRpU6v5Tk5O+vTTT21UOgBI/xgjHQBgqFatmubNm6datWopT548cnR0lLOzswoWLKg2bdpo6dKlyp49u62LCQAAAOAZefLk0fLly9W8eXP973//k7OzsxwdHZUnTx7Vq1dPS5YssXpWFgAgYRgjHQAAAAAAAAAAE/RIBwAAAAAAAADABEE6AAAAAAAAAAAmCNIBAAAAAAAAADDhaOsCJLfbtx/abN9ubi7y9w+y2f7TI+oscai3hKPOEod6SzjqLHGot4SjzhLHlvWWJ082m+w3rbBlO/15xecA0gvOVaQHnKdILzhXk1982+n0SE8mdnaSg4O97OxsXZL0gzpLHOot4aizxKHeEo46SxzqLeGos8Sh3vA84XxGesG5ivSA8xTpBeeqbRGkAwAAAAAAAABggiAdAAAAAAAAAAATBOkAAAAAAAAAAJggSAcAAAAAAAAAwARBOgAAAAAAAAAAJgjSAQAAAAAAAAAwQZAOAAAAAAAAAIAJgnQAAAAAAAAAAEwQpAMAAAAAAAAAYIIgHQAAAAAAAAAAEwTpAAAAAAAAAACYIEgHAAAAAAAAAMAEQToAAAAAAAAAACYI0gEAAAAAAAAAMGHTIP3p06fy9vZW//79Y11m165datKkiTw8PNSgQQPt2LEjFUsIAAAAPF/8/PzUrl07eXl5qWrVqurbt6/8/f1jXDautvisWbP05ptvysPDQ97e3rpw4UJqHAIAAACQ6mwapE+ZMkWHDh2Kdf7FixfVvXt3ffHFFzp06JC6d++unj176ubNm6lYSuD/tXfvcVHW+f//n6OgHFIR8ZBmqynoegoUD+XZNM9KSrFrmecsVJRVW+2ombp+U8tjtoqaaaXLR8tMs5OalkEqtZiLSmWQlgdQExAQmd8f/px1FrhkJphhhsf9duN2a67rPe/rPa95d/Hm6TXXAAAAuIfs7GyNHTtWISEhOnDggHbs2KFLly7pmWeeKdD2dmvxbdu26a233lJMTIzi4uLUvHlzRUVFyWw2O/plAQAAAKXOaUH6wYMH9fHHH+vBBx8sss22bdsUGhqqnj17ysPDQ/369VPbtm21efNmB44UAAAAcA9nzpxR06ZNNWHCBFWqVEnVq1dXRESEvvnmmwJtb7cW37Jli4YNG6bAwEBVrlxZU6dO1ZkzZxQXF+folwUAAACUOg9nHDQtLU3PPvusVq5cqfXr1xfZLjk5WUFBQVbbGjdurKSkJMP+TaaSGKVtbh7TGcd2VdTMPtTNdtTMPiaTlJKSouTkn1VSFxfWqFFDd91Vv2Q6K4OYa/ahbrajZvahbtI999yjNWvWWG3bvXu3mjdvXqDt7dbiycnJGjdunGWfp6enGjRooKSkJHXo0KHQ45fn2pc05jNcBXMVroB5ClfBXHUuhwfp+fn5mj59ukaNGqWmTZsats3MzJS3t7fVNi8vL2VlZRX5HH9/X1Ws6Lw71tSoUcVpx3ZV1Mw+1M121Mw2KSkpavLnpsrOulpifXr5eOv4f5J09913l1ifZRFzzT7UzXbUzD7U7Qaz2azXXntNe/bs0caNGwvsv91a3Na1urPX6bZYHp3s7CEUk+vc8nLiq42dPQS34zrzVHKVuco8BWsEuArmqnM4PEh/4403VKlSJQ0fPvy2bb29vZWdnW21LTs7W76+vkU+Jz0902lXpNeoUUVpaVdK7MpNd0fN7EPdbEfN7JOc/LOys64qaGof+dzl/4f7y/olXScWfaSTJ3+Wj0/1Ehhh2cNcsw91sx01s4+z6xYQUHb+4MnIyNDMmTP1/fffa+PGjWrSpEmBNrdbi9u6VnfWOh1lw4ULV5w9BOC2mKfll7PXCEBxMVdLR3HX6Q4P0t9//32dO3dOoaGhkmRZfH/66acFvng0KChI33//vdW25ORktWjRwvAYzpxIZrNzj++KqJl9qJvtqJltbtbK5y5/3dG4dqn07a6Ya/ahbrajZvYp73VLSUnRuHHjVLduXcXGxsrfv/B/LL3dWjwwMFAnT55U9+7dJUnXrl3TqVOnCtwO5lblue7lHe89XAHzFOV9jQDXwVx1Dod/tvKjjz7SkSNHdOjQIR06dEgDBgzQgAEDCoTokjRo0CDFx8dr586dysvL086dOxUfH6/Bgwc7etgAAACAy7t8+bJGjBih1q1bKyYmpsgQXbr9Wnzo0KHauHGjkpKSlJOTo0WLFikgIMBywQwAAADgTsrcTQpDQkK0fft2SVKjRo20YsUKvfHGG2rbtq1WrlypZcuWqWHDhk4eJQAAAOB6tm7dqjNnzmjXrl1q06aNQkJCLD+SbWvx8PBwjRw5UhMmTFCHDh107NgxvfHGG/L09HTa6wMAAABKi8Nv7fK//vGPf1g9TkhIsHrcuXNnde7c2ZFDAgAAANzSqFGjNGrUqCL327IWN5lMGj16tEaPHl2iYwQAAADKojJ3RToAAAAAAAAAAGUJQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABjwcMZBDx48qMWLF+uHH36Qt7e3+vTpo+nTp8vLy6tA27FjxyouLk4eHv8d6pIlS9SlSxdHDhkAAABwK+np6YqIiNDLL7+s9u3bF9g/duxYHT582GpbVlaWIiIi9NJLLyk/P19t2rSR2WyWyWSytPnyyy/l4+NT6uMHAAAAHMnhQXp6errGjx+vWbNmKSwsTBcuXNCYMWP0z3/+U1FRUQXaHz16VDExMWrXrp2jhwoAAAC4pcOHD2vGjBlKSUkpss2aNWusHsfGxmr58uWaOHGiJCk5OVnXrl3TkSNHVKlSpVIdLwAAAOBsDr+1i7+/v7766isNGTJEJpNJly5dUk5Ojvz9/Qu0TU1N1eXLl9WsWTNHDxMAAABwS9u2bdO0adMUHR1d7Of8+OOPmjNnjhYuXKhatWpJkhITE9WkSRNCdAAAAJQLTrm1yx133CFJ6tq1q86ePavQ0FANGTKkQLvExET5+voqOjpaiYmJCggI0MiRIxUeHm7Y/y2fLHWYm8d0xrFdFTWzD3WzHTWzT2nWy13fC+aafaib7aiZfajbDZ06ddLAgQPl4eFR7DB99uzZCgsLU2hoqGVbYmKicnJyNHToUJ0+fVqNGjXS1KlT1bp16yL7Ke+1L8947+EKmKflF2sEuArmqnM5JUi/6eOPP9bly5c1bdo0RUVFFfj4aG5uroKDgxUdHa3AwEDFxcVp0qRJ8vX1Vd++fQvt09/fVxUrOu87VGvUqOK0Y7sqamYf6mY7amYbPz/fUum3enVfBQS493vBXLMPdbMdNbNPea9bzZo1bWp/6NAhfffdd1q4cKHVdi8vL7Vq1UqTJ09WtWrVtGnTJo0ZM0bbt29X/fr1C/Tj7HW6bc46ewBux91/9zsH87SkMU9R3tcIcB3MVedwapDu5eUlLy8vTZ8+XQ8//LAuX76satWqWfaHhYUpLCzM8rhTp04KCwvTrl27igzS09MznXZFeo0aVZSWdkVms+OP74qomX2om+2omX0uXcoslX4vXszUhQtXSqVvZ2Ou2Ye62Y6a2cfZdXPVgGbz5s3q27dvgQB+xowZVo/HjBmjrVu3at++fXrssccK9OOsdTrKBnf93Q/3wjwtv5y9RgCKi7laOoq7Tnd4kH7kyBE988wz2r59u+V+irm5ufL09JS3t7dV29jY2AJXn+fm5qpy5cqGx3DmRDKbnXt8V0TN7EPdbEfNbFOatXL394G5Zh/qZjtqZh/qVnx5eXn67LPPtGLFigL7Xn31VfXu3dvq+4xut1an7uUX7z1cAfMUrBHgKpirzuHwz1Y2adJE2dnZWrRokXJzc3X69GktWLBA4eHhBb6oKCMjQ3PmzNGxY8eUn5+vvXv3aseOHYqIiHD0sAEAAIBy5/jx48rJySn0vucnTpzQ3Llzdf78eeXm5mr58uXKyMhQr169nDBSAAAAoHQ5PEj39fXVmjVrdPLkSXXs2FHDhw/X/fffr2eeeUaSFBISou3bt0uSRowYoccee0wTJ05USEiIFi5cqAULFlh9yREAAACAknHrWlySUlNTVa1atUKvMp8/f77uvvtuDR48WO3bt1d8fLzWrVsnPz8/B44YAAAAcAyn3CO9cePGWrt2baH7EhISLP9tMpkUGRmpyMhIRw0NAAAAKDeOHz9u9fjWtbgk9enTR3369Cn0uX5+fpo/f36pjQ0AAAAoSxx+RToAAAAAAAAAAK6EIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAw4JUg/ePCgHn74YbVu3VodO3bUnDlzlJ2dXWjbffv2aeDAgQoODlbfvn21Z88eB48WAAAAcD/p6enq1auX4uLiimwzduxYtWzZUiEhIZafL774wrJ/9erV6tKli4KDgzV8+HD9+OOPjhg6AAAA4HAOD9LT09M1fvx4/fWvf9WhQ4e0bds2xcfH65///GeBtqdOndKkSZM0efJkHTp0SJMmTdKUKVN09uxZRw8bAAAAcBuHDx9WRESEUlJSDNsdPXpUMTExSkhIsPx06dJFkrRt2za99dZbiomJUVxcnJo3b66oqCiZzWZHvAQAAADAoRwepPv7++urr77SkCFDZDKZdOnSJeXk5Mjf379A223btik0NFQ9e/aUh4eH+vXrp7Zt22rz5s2OHjYAAADgFrZt26Zp06YpOjrasF1qaqouX76sZs2aFbp/y5YtGjZsmAIDA1W5cmVNnTpVZ86cMbzCHQAAAHBVHs446B133CFJ6tq1q86ePavQ0FANGTKkQLvk5GQFBQVZbWvcuLGSkpIM+zeZSm6sxXXzmM44tquiZvahbrajZvYpzXq563vBXLMPdbMdNbMPdbuhU6dOGjhwoDw8PAzD9MTERPn6+io6OlqJiYkKCAjQyJEjFR4eLunGWn3cuHGW9p6enmrQoIGSkpLUoUOHQvss77Uvz3jv4QqYp+UXawS4CuaqczklSL/p448/1uXLlzVt2jRFRUVpzZo1VvszMzPl7e1ttc3Ly0tZWVlF9unv76uKFZ33Hao1alRx2rFdFTWzD3WzHTWzjZ+fb6n0W726rwIC3Pu9YK7Zh7rZjprZp7zXrWbNmsVql5ubq+DgYEVHRyswMFBxcXGaNGmSfH191bdvX5vX6s5ep9uGW0mWNHf/3e8czNOSxjxFeV8jwHUwV53DqUG6l5eXvLy8NH36dD388MO6fPmyqlWrZtnv7e1d4EtIs7Oz5etbdLiTnp7ptCvSa9SoorS0K+K2kMVDzexD3WxHzexz6VJmqfR78WKmLly4Uip9OxtzzT7UzXbUzD7OrpurBTRhYWEKCwuzPO7UqZPCwsK0a9cu9e3b1+a1urPW6Sgb3PV3P9wL87T8cvYaASgu5mrpKO463eFB+pEjR/TMM89o+/btqlSpkqQbV7t4enoWuKIlKChI33//vdW25ORktWjRwvAYzpxIZrNzj++KqJl9qJvtqJltSrNW7v4+MNfsQ91sR83sQ92KJzY21nL1+U25ubmqXLmyJCkwMFAnT55U9+7dJUnXrl3TqVOnCtya8VbUvfzivYcrYJ6CNQJcBXPVORz+2comTZooOztbixYtUm5urk6fPq0FCxYoPDzcEqzfNGjQIMXHx2vnzp3Ky8vTzp07FR8fr8GDBzt62AAAAEC5kpGRoTlz5ujYsWPKz8/X3r17tWPHDkVEREiShg4dqo0bNyopKUk5OTlatGiRAgICFBoa6uSRAwAAACXP4Vek+/r6as2aNZo3b546duyoKlWqaODAgZowYYIkKSQkRLNnz9agQYPUqFEjrVixQgsXLtSzzz6revXqadmyZWrYsKGjhw0AAAC4vVvX4iNGjFBWVpYmTpyotLQ01a9fXwsWLLAE5eHh4bpy5YomTJig9PR0tWzZUm+88YY8PT2d/CoAAACAkueUe6Q3btxYa9euLXRfQkKC1ePOnTurc+fOjhgWAAAAUK4cP37c6vGta3GTyaTIyEhFRkYW+lyTyaTRo0dr9OjRpTpGAAAAoCxw+K1dAAAAAAAAAABwJQTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABgwClBelJSkkaNGqV27dqpY8eOevrpp5Wenl5o27Fjx6ply5YKCQmx/HzxxRcOHjEAAADgXtLT09WrVy/FxcUV2eadd95R7969FRISot69e2vTpk2Wffn5+QoJCVFwcLDVWj0rK8sRwwcAAAAcysPRB8zOztbYsWP1yCOP6I033lBmZqb+/ve/65lnntGqVasKtD969KhiYmLUrl07Rw8VAAAAcEuHDx/WjBkzlJKSUmSbTz/9VIsXL9bq1at177336ttvv9UTTzyhgIAA9e7dW8nJybp27ZqOHDmiSpUqOXD0AAAAgOM5/Ir0M2fOqGnTppowYYIqVaqk6tWrKyIiQt98802Btqmpqbp8+bKaNWvm6GECAAAAbmnbtm2aNm2aoqOjDdudPXtW48aNU3BwsEwmk0JCQtS+fXvLuj0xMVFNmjQhRAcAAEC54PAr0u+55x6tWbPGatvu3bvVvHnzAm0TExPl6+ur6OhoJSYmKiAgQCNHjlR4eLjhMUymEh1ysdw8pjOO7aqomX2om+2omX1Ks17u+l4w1+xD3WxHzexD3W7o1KmTBg4cKA8PD8Mw/dFHH7V6nJaWpm+++UYzZ86UdGOtnpOTo6FDh+r06dNq1KiRpk6dqtatWxfZZ3mvfXnGew9XwDwtv1gjwFUwV53L4UH6rcxms1577TXt2bNHGzduLLA/NzdXwcHBio6OVmBgoOLi4jRp0iT5+vqqb9++hfbp7++rihWd9x2qNWpUcdqxXRU1sw91sx01s42fn2+p9Fu9uq8CAtz7vWCu2Ye62Y6a2ae8161mzZo2P+f8+fMaP368WrRooQEDBkiSvLy81KpVK02ePFnVqlXTpk2bNGbMGG3fvl3169cv0Iez1+m2OevsAbgdd//d7xzM05LGPEV5XyPAdTBXncNpQXpGRoZmzpyp77//Xhs3blSTJk0KtAkLC1NYWJjlcadOnRQWFqZdu3YVGaSnp2c67Yr0GjWqKC3tisxmxx/fFVEz+1A321Ez+1y6lFkq/V68mKkLF66USt/OxlyzD3WzHTWzj7Pr5qoBzbfffqvJkycrNDRU8+fPl4fHjT8hZsyYYdVuzJgx2rp1q/bt26fHHnusQD/OWqejbHDX3/1wL8zT8svZawSguJirpaO463SnBOkpKSkaN26c6tatq9jYWPn7+xfaLjY2tsDV57m5uapcubJh/86cSGazc4/viqiZfaib7aiZbUqzVu7+PjDX7EPdbEfN7EPdii82NlYvv/yyoqKiNHr0aKt9r776qnr37m31fUa3W6tT9/KL9x6ugHkK1ghwFcxV53D4ZysvX76sESNGqHXr1oqJiSkyRJduXLU+Z84cHTt2TPn5+dq7d6927NihiIgIB44YAAAAKH92796tWbNmadmyZQVCdEk6ceKE5s6dq/Pnzys3N1fLly9XRkaGevXq5YTRAgAAAKXL4Vekb926VWfOnNGuXbv00UcfWe1LSEhQSEiIZs+erUGDBmnEiBHKysrSxIkTlZaWpvr162vBggUKDQ119LABAAAAt3frWnz58uW6fv26oqKirNoMHDhQL730kubPn68FCxZo8ODBunr1qlq2bKl169bJz8/POYMHAAAASpHDg/RRo0Zp1KhRRe5PSEiw/LfJZFJkZKQiIyMdMTQAAACgXDl+/LjV41vX4h988IHhc/38/DR//vxSGRcAAABQ1jj81i4AAAAAAAAAALgSgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYsDlIj4uLK41xAAAAAAAAAABQJtkcpEdFRalnz55asWKFzpw5UxpjAgAAAAAAAACgzLA5SD9w4ICmT5+uo0ePqnfv3ho9erR27Nih3Nzc0hgfAAAAAAAAAABOZXOQ7unpqd69e+v111/Xvn371LNnT61du1adOnXS7NmzlZSUVBrjBAAAAAAAAADAKez+stG0tDR98MEHeu+995ScnKz27durcuXKGjlypFatWlWSYwQAAAAAAAAAwGk8bH3Chx9+qPfff19fffWV7rnnHg0ZMkSrVq2Sv7+/JKlr166aMGGCnnzyyRIfLAAAAAAAAAAAjmZzkD579mz1799f7777rlq0aFFgf8OGDTVy5MiSGBsAAAAAAAAAAE5nc5B+4MABpaamqnbt2pKkb7/9VlWqVFGjRo0kSXXq1FFUVFTJjhIAAAAAAAAAACex+R7pn332mcLCwnTq1ClJUkJCgh5++GHt27evpMcGAAAAAAAAAIDT2XxF+vLly7Vy5UrLbV1GjRqlxo0b65VXXlHXrl1LfIAAAAAAAAAAADiTzVek//rrr+rcubPVtk6dOunMmTMlNigAAAAAAAAAAMoKm4P0evXqaf/+/VbbDh48qLp165bYoAAAAAAAAAAAKCtsvrXLE088oQkTJujBBx9UvXr1dObMGX3yySdasGBBaYwPAAAAAAAAAACnsvmK9IEDB2r16tXy9PTU999/Ly8vL61du1a9e/cujfEBAAAAMJCRkeHsIQAAAABuz+Yr0iWpffv2at++fUmPBQAAAEAR2rVrp/j4+ALbu3XrpkOHDjlhRAAAAED5YXOQfvbsWb3++us6deqU8vPzrfZt2LChxAYGAAAAlHc///yzXnjhBZnNZmVkZOjxxx+32p+RkaGqVas6aXQAAABA+WFzkD5z5kxduHBB3bt3l6enZ2mMCQAAAICkP/3pT3rwwQd18eJFHTlyRO3atbPaX6lSJfXo0cNJowMAAADKD5uD9MTERO3evVv+/v6lMR4AAAAAt3j00UclSXfddZfCwsKcOxgAAACgnLI5SK9SpYoqVapUGmMBAAAAUISwsDD9+9//1k8//SSz2VxgHwAAAIDSY3OQHhkZqZkzZ2rcuHEKCAiw2le3bt0SGxgAAACA/1q8eLFWr16tmjVrysPjv8t4k8lEkA4AAACUMpuD9Oeee06S9Mknn0i6sXA3m80ymUz6z3/+U7KjAwAAACBJev/997Vq1Sp17drV2UMBAAAAyh2bg/TPPvusNMYBAAAAwEBWVpa6dOni7GEAAAAA5VIFW59Qr1491atXT5cvX9b333+vmjVrysvLS/Xq1SuN8QEAAACQ1K1bN33wwQfOHgYAAABQLtl8RXpaWpomTJigo0ePytPTU7GxsQoPD9fatWsVEhJSGmMEAAAAyr2cnBzNmDFDq1atKvBdRRs2bHDSqAAAAIDyweYgfd68eQoKCtK6devUpUsXNWrUSE888YT+3//7f3rnnXdKY4wAAABAuRcUFKSgoCBnDwMAAAAol2wO0r/++mt9+umn8vb2lslkkiSNHTtWa9euLfHBAQAAALhh4sSJzh4CAAAAUG7ZHKR7enoqOztb3t7eMpvNkqTMzEz5+vqW+OAAAAAA3DBz5swi982fP9+BIwEAAADKH5u/bLRHjx6aPn26Tp06JZPJpLS0NM2ePVtdu3YtjfEBAAAAKMTFixe1a9cu+fj4OHsoAAAAgNuz+Yr0qVOnaubMmerTp48kqVOnTuratateeumlEh8cAAAAgBsKu+r8q6++0ttvv+2E0QAAAADli81Buq+vr5YuXar09HT98ssvqlOnjmrVqlUaYwMAAABg4P7771dUVJSzhwEAAAC4PZuD9G+++cbq8c8//6yff/5ZktS2bduSGRUAAAAAQ3l5edqxY4f8/f2dPRQAAADA7dkcpA8fPrzAtgoVKujOO+/UZ599ViKDAgAAAGCtadOmMplMVtsqVqyoZ5991kkjAgAAAMoPm4P0pKQkq8fp6elasWKF6tWrV2KDAgAAAGBtw4YNVo8rVKigP/3pT6pZs6aTRgQAAACUHxX+aAf+/v6aPn263nzzzZIYDwAAAIBCtGvXTqGhofLy8tKFCxckSTVq1HDyqAAAAIDyweYr0gtz+fJl5eTklERXAAAAAApx/vx5Pfnkk0pKSpKfn58uXryoBg0aaO3atapTp46zhwcAAAC4NZuvSJ85c6bVz7Rp0/SXv/xF999/f7H7SEpK0qhRo9SuXTt17NhRTz/9tNLT0wttu2/fPg0cOFDBwcHq27ev9uzZY+uQAQAAAJe3YMECNWjQQPHx8fryyy8VFxenP//5z5o/f75d/aWnp6tXr16Ki4srss3t1uKrV69Wly5dFBwcrOHDh+vHH3+0aywAAABAWfeHb+1SuXJlDR8+XHPmzClW++zsbI0dO1YhISE6cOCAduzYoUuXLumZZ54p0PbUqVOaNGmSJk+erEOHDmnSpEmaMmWKzp49+0eHDQAAALiUr7/+WrNnz5avr68kqUqVKpo1a5YOHjxoc1+HDx9WRESEUlJSimxzu7X4tm3b9NZbbykmJkZxcXFq3ry5oqKiZDab7XuBAAAAQBlm861d7L3i5aYzZ86oadOmmjBhgipWrKhKlSopIiJCTz/9dIG227ZtU2hoqHr27ClJ6tevn7Zu3arNmzcrKirqD40DAAAAcCX5+fkymUxW20wmkzw9PW3qZ9u2bVq6dKmmT5+u6Ohow3ZGa/EtW7Zo2LBhCgwMlCRNnTpVW7ZsUVxcnDp06GDjqwMAAADKNpuD9OXLlxer3cSJEwvdfs8992jNmjVW23bv3q3mzZsXaJucnKygoCCrbY0bN1ZSUpLhsf/n7wuHuHlMZxzbVVEz+1A321Ez+5Rmvdz1vWCu2Ye62Y6a2cfV69a+fXvNmjVLs2fPlo+PjzIzMzVr1iy1a9fOpn46deqkgQMHysPDwzBIv91aPDk5WePGjbPs8/T0VIMGDZSUlFRkkO6qtccfx3sPV8A8Lb9cfY2A8oO56lw2B+knT57Uxx9/rKZNm6phw4b67bffdOTIETVr1szyMdP/vVKmKGazWa+99pr27NmjjRs3FtifmZkpb29vq21eXl7Kysoqsk9/f19VrPiH71hjtxo1qjjt2K6KmtmHutmOmtnGz8+3VPqtXt1XAQHu/V4w1+xD3WxHzezjqnWbPn265XuG/Pz8dOnSJTVq1Ej//Oc/beqnZs2axWp3u7W4rWt1Z6/TbcOtJEuau//udw7maUljnpaO5dHJzh5CMbnO/1MTX23s7CG4HdeZp5KrzFV3nKc2B+kVKlTQzJkz9fjjj1u2vf/++9qzZ49ee+21YveTkZGhmTNn6vvvv9fGjRvVpEmTAm28vb2VnZ1ttS07O9sS2BcmPT3TaVek16hRRWlpV8RtIYuHmtmHutmOmtnn0qXMUun34sVMXbhwpVT6djbmmn2om+2omX2cXbc/EtCYzWbl5eXpww8/1KFDh5SWlqbTp09rzJgxqlixYgmO8r9utxa3da3urHU6ygZ3/d0P98I8hatgrsIVuNI8Le463eYgfd++fVq4cKHVtgEDBmjevHnF7iMlJUXjxo1T3bp1FRsbK39//0LbBQUF6fvvv7falpycrBYtWhj278w/KM1m5x7fFVEz+1A321Ez25Rmrdz9fWCu2Ye62Y6a2cfV6paVlaXRo0crICBAy5cvV4cOHZSWlqbu3btr7969WrNmjXx8fEr8uLdbiwcGBurkyZPq3r27JOnatWs6depUgdvB3MqV6o6SxXsPV8A8hatgrsIVuOM8tfmzlf7+/vrmm2+stu3fv1916tQp1vMvX76sESNGqHXr1oqJiSkyRJekQYMGKT4+Xjt37lReXp527typ+Ph4DR482NZhAwAAAC7p9ddfl6enp2bPnm3ZVqNGDe3Zs0d5eXl64403SuW4t1uLDx06VBs3blRSUpJycnK0aNEiBQQEKDQ0tFTGAwAAADiTzVekjx8/Xk888YR69+6tunXrKjU1VXv27NGyZcuK9fytW7fqzJkz2rVrlz766COrfQkJCQoJCdHs2bM1aNAgNWrUSCtWrNDChQv17LPPql69elq2bJkaNmxo67ABAAAAl7R7926tXr1aNWrUsNpeo0YNzZ49W1OmTDH80lBb2LIWDw8P15UrVzRhwgSlp6erZcuWeuONN+Tp6VkiYwEAAADKEpuD9Icfflj16tXT9u3bdezYMdWvX1/vvvtuofc4L8yoUaM0atSoIvcnJCRYPe7cubM6d+5s6zABAAAAt5CWlqY//elPhe7785//rPPnz9vd9/Hjx60e27IWN5lMGj16tEaPHm338QEAAABXYXOQLkn333+/7r//fqWnpxvemgUAAADAH3PHHXfo4sWLql69eoF9ly5dkre3txNGBQAAAJQvNt8j/dq1a3r11VfVpk0b9ejRQ6mpqRo6dKjOnTtXGuMDAAAAyrX77rtPmzZtKnTf22+/reDgYMcOCAAAACiHbL4iffny5fr666+1ZMkSRUdHq0aNGqpTp47mzp2rJUuWlMYYAQAAgHJr/PjxGjJkiC5evKh+/fqpZs2aOnfunHbt2qX/+7//08aNG509RAAAAMDt2Rykf/DBB3rnnXdUu3ZtmUwm+fj4aP78+erVq1dpjA8AAAAo1xo2bKiYmBi9+OKL2rRpk0wmk8xms4KCgrR69Wq1aNHC2UMEAAAA3J7NQXpWVpblvuhms1mS5OXlpQoVbL5LDAAAAIBiaN26tT744AOlpqYqPT1dNWvWVN26dZ09LAAAAKDcsDn9Dg4O1vLlyyVJJpNJkvTWW2+pZcuWJTsyAAAAAFbq16+ve++9lxAdAAAAcDCbr0h/5plnNHLkSG3btk2ZmZnq16+fMjMztW7dutIYHwAAAAAAAAAATmVzkB4QEKAPP/xQe/fu1enTp1WnTh1169ZNd9xxR2mMDwAAAAAAAAAAp7I5SB8wYIC2b9+uvn37lsZ4AAAAAAAAAAAoU+z6htCrV6+W9DgAAAAAAAAAACiTbL4ivX379nr44YfVpUsX1apVy2rfxIkTS2xgAAAAAAAAAACUBTYH6b/88ovq16+vn376ST/99JNlu8lkKtGBAQAAAAAAAABQFhQ7SB8zZoxiYmL01ltvSZKys7Pl5eVVagMDAAAAAAAAAKAsKPY90hMSEqwed+nSpcQHAwAAAAAAAABAWWPXl41KktlsLslxAAAAAAAAAABQJtkdpHNPdAAAAAAAAABAeWB3kA4AAAAAAAAAQHlQ7C8bzcvL03vvvWd5fO3aNavHkhQWFlZCwwIAAAAAAAAAoGwodpAeEBCgpUuXWh5Xr17d6rHJZCJIBwAAAAAAAAC4nWIH6Z9//nlpjgMAAAAAAAAAgDKJe6QDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMCAhzMPnp6eroiICL388stq3759oW3Gjh2ruLg4eXj8d6hLlixRly5dHDVMAAAAwG2kpaXp+eefV3x8vCpWrKhBgwbp73//u9V6W7qxDj98+LDVtqysLEVEROill15Sfn6+2rRpI7PZLJPJZGnz5ZdfysfHxyGvBQAAAHAUpwXphw8f1owZM5SSkmLY7ujRo4qJiVG7du0cNDIAAADAfU2ZMkW1a9fW/v37deHCBT311FNav369xo4da9VuzZo1Vo9jY2O1fPlyTZw4UZKUnJysa9eu6ciRI6pUqZLDxg8AAAA4g1Nu7bJt2zZNmzZN0dHRhu1SU1N1+fJlNWvWzEEjAwAAANzXzz//rPj4eE2fPl3e3t6qX7++IiMjtWnTJsPn/fjjj5ozZ44WLlyoWrVqSZISExPVpEkTQnQAAACUC065Ir1Tp04aOHCgPDw8DMP0xMRE+fr6Kjo6WomJiQoICNDIkSMVHh5u2P8tnyx1mJvHdMaxXRU1sw91sx01s09p1std3wvmmn2om+2omX2om3Ty5En5+fmpdu3alm2NGjXSmTNn9Pvvv6tq1aqFPm/27NkKCwtTaGioZVtiYqJycnI0dOhQnT59Wo0aNdLUqVPVunXrIo9fnmtf3vHewxUwT+EqmKtwBe44T50SpNesWbNY7XJzcxUcHKzo6GgFBgYqLi5OkyZNkq+vr/r27Vvoc/z9fVWxovO+Q7VGjSpOO7aromb2oW62o2a28fPzLZV+q1f3VUCAe78XzDX7UDfbUTP7lOe6ZWZmytvb22rbzcdZWVmFBumHDh3Sd999p4ULF1pt9/LyUqtWrTR58mRVq1ZNmzZt0pgxY7R9+3bVr1+/QD/OXqfb5qyzB+B23P13v3MwT0sa87S0MFdLGnO1NDBPS5o7zlOnftno7YSFhSksLMzyuFOnTgoLC9OuXbuKDNLT0zOddkV6jRpVlJZ2RWaz44/viqiZfaib7aiZfS5dyiyVfi9ezNSFC1dKpW9nY67Zh7rZjprZx9l1Kwt/TPj4+Ojq1atW224+9vUt/B9QN2/erL59+xa4GGbGjBlWj8eMGaOtW7dq3759euyxxwr046x1OsoGd/3dD/fCPIWrYK7CFbjSPC3uOr1MB+mxsbEFrj7Pzc1V5cqVDZ/nzD8ozWbnHt8VUTP7UDfbUTPblGat3P19YK7Zh7rZjprZpzzXLTAwUJcuXdKFCxcUEBAgSfrhhx9Up04dValS8A+IvLw8ffbZZ1qxYkWBfa+++qp69+5t9X1Gt1url9e6g/ceroF5ClfBXIUrcMd5WqY/W5mRkaE5c+bo2LFjys/P1969e7Vjxw5FREQ4e2gAAACAy2nQoIHatGmjefPmKSMjQ6mpqVq5cmWR30F0/Phx5eTkFHrf8xMnTmju3Lk6f/68cnNztXz5cmVkZKhXr16l/TIAAAAAhytzQXpISIi2b98uSRoxYoQee+wxTZw4USEhIVq4cKEWLFhg9SVHAAAAAIpv6dKlysvL0wMPPKBHHnlEnTt3VmRkpCTrtbgkpaamqlq1aoVeZT5//nzdfffdGjx4sNq3b6/4+HitW7dOfn5+jnopAAAAgMM4/dYux48ft3qckJBg+W+TyaTIyEjLwh4AAADAHxMQEKClS5cWuu/Wtbgk9enTR3369Cm0rZ+fn+bPn1/i4wMAAADKojJ3RToAAAAAAAAAAGUJQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwIBTg/T09HT16tVLcXFxRbbZt2+fBg4cqODgYPXt21d79uxx4AgBAAAA95KWlqbIyEiFhoaqffv2mjt3rvLy8gptO3bsWLVs2VIhISGWny+++MKyf/Xq1erSpYuCg4M1fPhw/fjjj456GQAAAIBDOS1IP3z4sCIiIpSSklJkm1OnTmnSpEmaPHmyDh06pEmTJmnKlCk6e/asA0cKAAAAuI8pU6bIx8dH+/fvV2xsrA4ePKj169cX2vbo0aOKiYlRQkKC5adLly6SpG3btumtt95STEyM4uLi1Lx5c0VFRclsNjvw1QAAAACO4eGMg27btk1Lly7V9OnTFR0dbdguNDRUPXv2lCT169dPW7du1ebNmxUVFVXk80ymEh/ybZlMUkpKipKTf1ZJ/e1Qo0YN3XVX/ZLprAy6+T454/1yZdTNdtTMPqVZL3d9L5hr9qFutisvNfvll1SlpaWVWH8mk9S48Z/k61u9xPp0NT///LPi4+P1xRdfyNvbW/Xr11dkZKReeeUVjR071qptamqqLl++rGbNmhXa15YtWzRs2DAFBgZKkqZOnaotW7YoLi5OHTp0KPQ57j5nUTTee7gC5ilcBXMVrsAd56lTgvROnTpp4MCB8vDwMAzSk5OTFRQUZLWtcePGSkpKKvI5/v6+qljR8Rfap6SkqMmfmyo762qJ9enl463j/0nS3XffXWJ9lkU1alRx9hBcEnWzHTWzjZ+fb6n0W726rwIC3Pu9YK7Zh7rZzp1rlpKSovs6hpbo2koqP+uropw8eVJ+fn6qXbu2ZVujRo105swZ/f7776pataple2Jionx9fRUdHa3ExEQFBARo5MiRCg8Pl3RjrT5u3DhLe09PTzVo0EBJSUmFBunOWqfbh0/AljR3/93vHMzTksY8LS3M1ZLGXC0NzNOS5o7z1ClBes2aNYvVLjMzU97e3lbbvLy8lJWVVeRz0tMznfIvHsnJPys766qCpvaRz13+f7i/rF/SdWLRRzp58mf5+LjnVVMm040AIC3tSoldxV8eUDfbUTP7XLqUWSr9XryYqQsXrpRK387GXLMPdbNdeajZyZMlu7aS/ru+Sk52zvqqLPwxUdj6+ubjrKwsqyA9NzdXwcHBio6OVmBgoOLi4jRp0iT5+vqqb9++Nq/VnbVOR9ngrr/74V6Yp3AVzFW4Aleap8VdpzslSC8ub29vZWdnW23Lzs6Wr6/xVZLO+IPy5jF97vLXHY1rGze2s293ZTa7/2ssDdTNdtTMNqVZK3d/H5hr9qFutisPNSuttZW7160oPj4+unrV+ir/m4//d40dFhamsLAwy+NOnTopLCxMu3btUt++fe1aq5fXuoP3Hq6BeQpXwVyFK3DHeVqmP1sZFBSkkydPWm1LTk623IcRAAAAQPEFBgbq0qVLunDhgmXbDz/8oDp16qhKFesrcWJjY7Vr1y6rbbm5uapcubKlr1vX6teuXdOpU6cK3JoRAAAAcAdlOkgfNGiQ4uPjtXPnTuXl5Wnnzp2Kj4/X4MGDnT00AAAAwOU0aNBAbdq00bx585SRkaHU1FStXLnSct/zW2VkZGjOnDk6duyY8vPztXfvXu3YsUMRERGSpKFDh2rjxo1KSkpSTk6OFi1apICAAIWGhjr6ZQEAAAClrszd2iUkJESzZ8/WoEGD1KhRI61YsUILFy7Us88+q3r16mnZsmVq2LChs4cJAAAAuKSlS5fqpZde0gMPPKAKFSooLCxMkZGRkqzX4iNGjFBWVpYmTpyotLQ01a9fXwsWLLAE5eHh4bpy5YomTJig9PR0tWzZUm+88YY8PT2d+fIAAACAUuH0IP348eNWjxMSEqwed+7cWZ07d3bkkAAAAAC3FRAQoKVLlxa679a1uMlkUmRkpCVk/18mk0mjR4/W6NGjS2WcAAAAQFlSpm/tAgAAAAAAAACAsxGkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAQ9nHDQtLU3PP/+84uPjVbFiRQ0aNEh///vf5eFRcDhjx45VXFyc1b4lS5aoS5cujhwyAAAA4BZsWYu/8847Wr9+vc6dO6datWrp8ccf16OPPipJys/PV5s2bWQ2m2UymSzP+fLLL+Xj4+Ow1wMAAAA4glOC9ClTpqh27drav3+/Lly4oKeeekrr16/X2LFjC7Q9evSoYmJi1K5dOyeMFAAAAHAvxV2Lf/rpp1q8eLFWr16te++9V99++62eeOIJBQQEqHfv3kpOTta1a9d05MgRVapUyUmvBgAAAHAMhwfpP//8s+Lj4/XFF1/I29tb9evXV2RkpF555ZUCi/fU1FRdvnxZzZo1s+kYt1wQ4zCleUxnvB5HuPm63PX1lRbqZjtqZh/Oa7ZjrtmHutmOmv0xJlP5rZ0ta/GzZ89q3LhxCg4OliSFhISoffv2+uabb9S7d28lJiaqSZMmNoXo5bXu4L2Ha2CewlUwV+EK3HGeOjxIP3nypPz8/FS7dm3LtkaNGunMmTP6/fffVbVqVcv2xMRE+fr6Kjo6WomJiQoICNDIkSMVHh5eZP/+/r6qWNHxt3738/MtlX6rV/dVQECVUum7rKhRw71fX2mhbrajZrbhvGY/5pp9qJvt3Llm1auXzjlIunF+c/fzUFFsWYvfvIXLTWlpafrmm280c+ZMSTfW6jk5ORo6dKhOnz6tRo0aaerUqWrdunWhx3bWOt0+Z509ALdTXv+fK13M05LGPC0tzNWSxlwtDczTkuaO89ThQXpmZqa8vb2ttt18nJWVZbV4z83NVXBwsKKjoxUYGKi4uDhNmjRJvr6+6tu3b6H9p6dnOuVfPC5dyiyVfi9ezNSFC1dKpW9nM5luBABpaVdkNjt7NK6DutmOmtmH85rtmGv2oW62Kw81u3ixdM5B0o3zmzPOQ2Xhjwlb1uK3On/+vMaPH68WLVpowIABkiQvLy+1atVKkydPVrVq1bRp0yaNGTNG27dvV/369Qv04ax1OsoGd/3dD/fCPIWrYK7CFbjSPC3uOt3hQbqPj4+uXr1qte3mY19f6yuPwsLCFBYWZnncqVMnhYWFadeuXUUG6ZKc8gdlaR7TXf9Avslsdv/XWBqom+2omW04r9mPuWYf6mY7amaf8lw3W9biN3377beaPHmyQkNDNX/+fMuXks6YMcOq3ZgxY7R161bt27dPjz32WKF9lde6g/ceroF5ClfBXIUrcMd56vDPVgYGBurSpUu6cOGCZdsPP/ygOnXqqEoV6/Q/NjZWu3btstqWm5urypUrO2SsAAAAgDuxZS0u3ViPjxw5UiNGjNCiRYus7of+6quv6tixY1btWasDAADAXTk8SG/QoIHatGmjefPmKSMjQ6mpqVq5cmWh9z3PyMjQnDlzdOzYMeXn52vv3r3asWOHIiIiHD1sAAAAwOXZshbfvXu3Zs2apWXLlmn06NEF9p84cUJz587V+fPnlZubq+XLlysjI0O9evVyxEsBAAAAHMop3/azdOlS5eXl6YEHHtAjjzyizp07KzIyUpIUEhKi7du3S5JGjBihxx57TBMnTlRISIgWLlyoBQsWKDQ01BnDBgAAAFxecdfiy5cv1/Xr1xUVFaWQkBDLzwsvvCBJmj9/vu6++24NHjxY7du3V3x8vNatWyc/Pz9nvTQAAACg1Dj8HumSFBAQoKVLlxa6LyEhwfLfJpNJkZGRloU9AAAAgD+muGvxDz74wLAfPz8/zZ8/v0THBgAAAJRVTrkiHQAAAAAAAAAAV0GQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABgjSAQAAAAAAAAAwQJAOAAAAAAAAAIABgnQAAAAAAAAAAAwQpAMAAAAAAAAAYIAgHQAAAAAAAAAAAwTpAAAAAAAAAAAYIEgHAAAAAAAAAMAAQToAAAAAAAAAAAYI0gEAAAAAAAAAMECQDgAAAAAAAACAAYJ0AAAAAAAAAAAMEKQDAAAAAAAAAGCAIB0AAAAAAAAAAAME6QAAAAAAAAAAGCBIBwAAAAAAAADAAEE6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwABBOgAAAAAAAAAABpwSpKelpSkyMlKhoaFq37695s6dq7y8vELb7tu3TwMHDlRwcLD69u2rPXv2OHi0AAAAgPsoybX46tWr1aVLFwUHB2v48OH68ccfHfESAAAAAIdzSpA+ZcoU+fj4aP/+/YqNjdXBgwe1fv36Au1OnTqlSZMmafLkyTp06JAmTZqkKVOm6OzZs44fNAAAAOAGSmotvm3bNr311luKiYlRXFycmjdvrqioKJnNZge/IgAAAKD0eTj6gD///LPi4+P1xRdfyNvbW/Xr11dkZKReeeUVjR071qrttm3bFBoaqp49e0qS+vXrp61bt2rz5s2Kiooq8hgmU6m+BMNjZv2SXiL93ezn5MnjJdLfTRUqVFB+fn6Z6NNkkvz8fHXpUqZu/XurLI3RkX0Wt7+i6vZH+rSFs173H+nTlpoVt88/yhXem5vnH85rxcd5zb7+OK/Z3md5OK+V9Dno1r5MJuesF8uCklyLb9myRcOGDVNgYKAkaerUqdqyZYvi4uLUoUOHQo9fXusO3nu4BuYpXAVzFa7AHeepw4P0kydPys/PT7Vr17Zsa9Sokc6cOaPff/9dVatWtWxPTk5WUFCQ1fMbN26spKSkIvuvWbNKyQ+6GHr06FzyV98sLNnuAMAWDzzQWU8+Ofb2DW3BeQ1AMZXKOUgq9+ehklyLJycna9y4cZZ9np6eatCggZKSkgoN0p21TrfHxFddZ6wov5incBXMVbgC5imKw+G3dsnMzJS3t7fVtpuPs7KybtvWy8urQDsAAAAAt1eSa3HW6gAAAChPHB6k+/j46OrVq1bbbj729fW12u7t7a3s7GyrbdnZ2QXaAQAAALi9klyLs1YHAABAeeLwID0wMFCXLl3ShQsXLNt++OEH1alTR1WqWH+MIigoSCdPnrTalpycbLkPIwAAAIDiK8m1eGBgoNX+a9eu6dSpUwVuBwMAAAC4A4cH6Q0aNFCbNm00b948ZWRkKDU1VStXrlR4eHiBtoMGDVJ8fLx27typvLw87dy5U/Hx8Ro8eLCjhw0AAAC4vJJciw8dOlQbN25UUlKScnJytGjRIgUEBCg0NNTRLwsAAAAodSZziX9D5u1duHBBL730kuLi4lShQgWFhYVp2rRpqlixokJCQjR79mwNGjRIkrR//34tXLhQKSkpqlevnqZPn66uXbs6esgAAACAWyiptbjZbNa6deu0adMmpaenq2XLlpo9e7YaNmzozJcHAAAAlAqnBOmuYPv27XrxxRettl27dk2SdPTo0QLt9+3bp4ULFyo1NVV33nmnnn76aXXv3t2yf/Xq1Xrrrbf0+++/W/7IuOeee0r3RTiYrTV75513tH79ep07d061atXS448/rkcffVSSlJ+frzZt2shsNstkMlme8+WXX8rHx6cUX4Xj2Vq3sWPHKi4uTh4eHpZtS5YsUZcuXSQx1/63ZmPHjtXhw4ettmVlZSkiIkIvvfRSuZprkvT9999r3rx5On78uLy8vNSnTx89/fTTqlSpUoG2nNdusKVmnNf+y5a6cV67obg147xm7YcfftC8efP03Xff6Y477lBERITGjx+vChUKfvCS8xoAAAAAu5lRLL/99pu5Y8eO5vfee6/Avp9++sncsmVL8yeffGK+du2a+cMPPzS3atXK/Ntvv5nNZrN569at5s6dO5tPnDhhzs7ONs+fP9/cv39/c35+vqNfhkMZ1eyTTz4xh4aGmhMSEsz5+fnmI0eOmENDQ80fffSR2Ww2m48fP25u3ry5OScnx9HDdjqjupnNZnP79u3NcXFxhe5jrhVes1v961//Mnft2tV89uxZs9lcvuba9evXzR07djS/+eab5uvXr5t//fVXc+/evc3Lly8v0Jbz2g221Izz2n/ZUjezmfOa2Wx7zW5Vns9rGRkZ5m7dupmfffZZc2ZmpvmXX34xDxgwwLxs2bICbTmvwZUdOnTI2UMAALd1/fp18/nz5825ubmWbWlpaeViLQXANg6/R7orMpvNmj59urp161bo/dm3bdum0NBQ9ezZUx4eHurXr5/atm2rzZs3S5K2bNmiYcOGKTAwUJUrV9bUqVN15swZxcXFOfqlOMztanb27FmNGzdOwcHBMplMCgkJUfv27fXNN99IkhITE9WkSZNCr1x0Z7erW2pqqi5fvqxmzZoV+nzmmvH3J/z444+aM2eOFi5cqFq1akkqX3Pt8uXLOn/+vPLz82X+/z+MVKFCBXl7exdoy3ntBltqxnntv2ypG+e1G2yp2a3K+3nt8OHDSktL0wsvvCAfHx/Vq1dPTz31lN555x1LHW/ivAZXNm7cOGcPAbBJZmamDhw4oB07dujgwYPKyspy9pCAAs6fP6/o6Gjde++96ty5s1q3bq2oqCidOXNGixcv1vvvv+/sIaKcGzNmjNXj7OxsJ40ENxGkF8P777+v5ORkzZgxo9D9ycnJCgoKstrWuHFjJSUlFbrf09NTDRo0sOx3R7er2aOPPqonnnjC8jgtLU3ffPONWrRoIelGCJCTk6OhQ4eqQ4cOevTRR3XkyBGHjN2Zble3xMRE+fr6Kjo6Wh06dNCAAQMUGxtr2c9cMzZ79myFhYVZfQlaeZpr1atX18iRI7VgwQK1bNlSXbt2VYMGDTRy5MgCbTmv3WBLzTiv/ZctdeO8doMtNbtVeT+v5efny9PTU56enpZtJpNJFy5c0O+//27VlvMaXNn//sMQUJatWbNGHTt21NixYzVt2jSNGjVKnTt31qZNm5w9NMDi8uXLeuSRR/Tbb79p1qxZWrNmjWbPnq2LFy8qIiJC8fHxlu8LAZwlISHB6vHNW1/CeQjSbyM/P1+vv/66nnzySd1xxx2FtsnMzCxwxZiXl5flX91vt9/dFKdmtzp//rzGjRunFi1aaMCAAZJu1KdVq1ZauXKl9u7dqx49emjMmDFKTU0t7eE7TXHqlpubq+DgYEVHR2v//v2aMWOG5s6dq127dklirhk5dOiQvvvuO02cONFqe3maa/n5+fLy8tLzzz+vb7/9Vjt27NAPP/ygpUuXFmjLee0GW2p2q/J+XrOlbpzXbrBnrnFek1q3bi0vLy8tWrRIV69e1enTpxUTEyOp4BU7nNfgym79vgOgLPvXv/6lVatW6dlnn9X+/ft19OhR7du3T9OmTdOSJUu0e/duZw8RkCStWrVKLVq00Ntvv62hQ4eqY8eOGjJkiN58801VrFhRHTp0UOXKlZ09TMAK/7DufATptxEXF6dz584pPDy8yDbe3t4F/ljLzs6Wr69vsfa7m+LU7KZvv/1W4eHhatiwoV5//XXLF83NmDFD8+bNU+3ateXl5aUxY8aobt262rdvX2kP32mKU7ewsDCtWbNGzZo1k6enpzp16qSwsDBL4MRcK9rmzZvVt29f1axZ02p7eZprn3zyiXbv3q1hw4apUqVKCgwM1IQJE/TOO+8UaMt57QZbanYT5zXb6sZ57QZ75hrnNalq1apavXq1vvvuO3Xr1k1TpkxRWFiYZd+tOK/BlV29elUPPPCA4Q9QFrz99tuaP3++Hn74YdWsWVMeHh6qXbu2/vrXv2rWrFl66623nD1EQJL0+eef629/+1uBf6j87LPPVLlyZX399ddOGhlQNP5h3fkI0m9j9+7d6tWrl3x8fIpsExQUpJMnT1ptS05OVmBgoCQpMDDQav+1a9d06tSpAh8vdhfFqZkkxcbGauTIkRoxYoQWLVpkdS/XV199VceOHbNqn5ub69b/IlycusXGxlrCpZturQtzrXB5eXn67LPPCv1oXnmaa7/++qtyc3Ottnl4eFjdEuEmzms32FIzifPaTbbUjfPaDbbONc5rN+Tm5iovL08bNmxQXFyc/vWvf6lChQpq3LhxgavLOa/BlXl6emrixImGP0BZcOrUKXXv3r3QfT179tSPP/7o4BEBhTt//rwaNmxYYHvt2rU1d+5cnT9/3gmjAlDWEaTfxuHDh9W2bVvDNoMGDVJ8fLx27typvLw87dy5U/Hx8ZYvPhw6dKg2btyopKQk5eTkaNGiRQoICLC6n6k7KU7Ndu/erVmzZmnZsmUaPXp0gf0nTpyw/PLKzc3V8uXLlZGRoV69epXWsJ2uOHXLyMjQnDlzdOzYMeXn52vv3r3asWOHIiIiJDHXinL8+HHl5OSodevWBfaVp7nWqVMnnT9/XqtWrdL169eVmpqq119/XQMHDizQlvPaDbbUjPPaf9lSN85rN9hSM4nz2q3GjBmj2NhYmc1mHT16VKtWrdKIESMKtOO8Blfm4eGhhx56yPAHKAtMJpPl03j/q1KlSnxRHsoMHx+fQsPyVq1a6e677+YTaSgT8vLy9N5771l+rl27ZvX4vffec/YQyx8zDAUHB5v37t1b6Pb333/f8viLL74wDxo0yBwcHGzu37+/1XPy8/PNMTEx5h49epiDg4PNw4cPN//4448OGb8zFKdmAwYMMDdt2tQcHBxs9fP888+bzWaz+eLFi+YZM2aY77vvPkvN/vOf/zj0dThaceqWn59vXrFihbl79+7mVq1amfv372/etWuXpS1z7b/bb/3/c9euXeb77ruv0D7K21z78ssvzQ8//LC5TZs25m7dupkXL15szsnJMZvNnNeKUtyacV6zVty6cV77L1v+/+S89l/x8fHmhx56yBwcHGx+4IEHzBs2bLDs47wGdxEcHOzsIQDFEhIS8of2A47yt7/9zbx06dJC9y1evNgcHR3t4BEBBXXv3t3wp0ePHs4eYrljMpu5Uz0AAAAAlFUvvviiZs+e7exhALfVqlUrvfTSS0Xuf/HFF/Xdd985cERA4ZKSkvTXv/5Vjz/+uB566CHVrVtXp0+f1pYtW/Tuu+9qy5Ytltu/AcBNBOkAAAAAAOAP69Gjx23bfP755w4YCXB7Bw4c0LPPPqtz585ZttWuXVvz58/Xfffd58SRASirCNIBAAAAAABQ7ly/fl0JCQk6d+6catWqpZCQEFWsWNHZwwJQRhGkAwAAAAAAAABgoIKzBwAAAAAAAAAAQFlGkA4AAAAAAAAAgAGCdAAAAAAAgHLiypUrSk9Pd/YwAMDlEKQDAAAAAAD8AT/99JP+/ve/q0uXLgoJCVHPnj21cOFCZWZmSpKaNGmiuLg4J4/yhl69eunkyZPOHgYAuByCdABwIeX16pFTp045ewgAAABAoY4cOaKHHnpI9erV03vvvaeEhAStXr1a3333nUaPHq3r1687e4hWLl686OwhAIBLIkgHABs582qSW68e2bp1q3r06GFzH0899ZQOHz5s2CYuLk5NmjSxa4wl7dixYxowYECp9J2SkqJhw4bp2rVrpdI/AAAA3N8LL7ygsLAwRUVFyd/fX5LUsGFDvfrqq6pRo4ZSU1MlSV9++aUGDx6skJAQhYeH68SJE5Y+YmNjNWTIELVv314hISEaP3685QKaZcuWafTo0Ro6dKjatWunb775Rj/88IPGjx+vbt26qVWrVurXr5/27Nlj6e/777/X8OHDFRISok6dOmnJkiUym83q3bu3JGncuHFavXq1JOmrr75SeHi4QkND1b9/f23fvt3Sz4wZMxQVFaW+ffuqQ4cOSklJKd1iAkAZRpAOAC7kj1498q9//Us+Pj5q06ZNCY2o9F25cqXUgu67775bbdu21cqVK0ulfwAAALi3lJQUnTx5stALPwICArRy5Uo1aNBAkhQfH6+YmBgdPHhQ1atX14IFCyRJ//73v/Xyyy9r1qxZiouL065du3Tq1Clt2LDB0tfBgwc1bdo07dmzRyEhIZo0aZKCgoL0ySef6NChQ+rUqZNmzZolSbp06ZJGjx6t9u3bKy4uTm+//ba2bt2qzZs3a/fu3ZKk1atXa9y4cUpKStJTTz2lJ554QnFxcZozZ47mzZun/fv3W469f/9+LVmyRB9//LHuvvvuUqokAJR9BOkAUMI+/PBDDRw4UG3atNGQIUN04MABy77hw4dr0aJFevTRRxUSEqK+fftq586dlv2//PKLxowZo9atW6tPnz5av3695crwwq4eycvL08KFC9WtWze1bt1azz33nPLy8godV25urpYvX67HH3/csq2oK1VuiomJUa9evRQcHKyoqChlZGRY+lqwYIH69u2rkJAQ3XfffZozZ47lucOHD9eMGTPUvXt3devWTRkZGfr888/1l7/8Rffdd5/uvfdePfbYY1a3bPnggw80YMAAq7qkpqZq3LhxkqSQkBAlJCTIbDZrw4YN6t27t0JDQzVs2DAdPXrU0k+PHj30wgsvqGPHjgoLC1Nubq5mzZqljh07qn379ho2bJjVFfnDhg3Tm2++WS5vmQMAAIA/5uYaMiAg4LZtR40apYCAAHl5ealnz56Wq7uDgoK0Y8cOtWrVSpcvX9a5c+fk7++vs2fPWp5bv3593XffffL19ZWHh4feeOMNTZo0SWazWadPn1bVqlUt7ffs2aPKlStrwoQJqlSpku6++26tW7dO3bp1KzCmd999Vw888IAefPBBVaxYUa1bt9YjjzyiTZs2WdoEBwcrKChIVatW/SOlAgCXR5AOACVo3759evHFF/XCCy8oPj5ekyZN0qRJk6y+zGfLli169tlnFRcXpwcffFAvvPCCcnJydP36dY0fP161atXSgQMHFBMTo/fee8/yvP+9ekSSzp49q6pVq+rTTz/Vli1btGPHDn300UeFju2zzz5TpUqVdO+990oyvlLlptOnT2vHjh3avXu3vv32W8uC+s0339T+/fv15ptvKiEhQStXrtS7776rr7/+2vLcr776Su+++662b9+ujIwMTZ48WU888YQOHjyovXv3ymw2a8WKFZJu3ErmmWee0fTp03X48GHNnDlTTz/9tHJyciz/aJCQkKCQkBC9/fbbWrdunZYsWaKDBw9qyJAhGjVqlC5cuGA59r///W/t2rVLGzZs0AcffKCEhATt2rVLX331ldq2bavZs2db2tauXVstWrTQtm3bbH/DAQAAUK7VrFlTknT+/PlC99+6RvXz87P8t6enp+Xe6RUqVNCGDRt03333aciQIVq1apUyMjKsLnCpVauWVb9JSUkaOnSounTpoueee07Hjx+3tD9//rzuvPNOmUwmS/t77rlHderUKTC+06dP65NPPlFoaKjl56233tKvv/5a5LEBoLwiSAeAErRx40b99a9/Vdu2bVWxYkV1795dPXr00Lvvvmtp07t3bzVr1kyVKlXSQw89pCtXrigtLU3ffvutTp06peeff14+Pj6qV6+eoqOjDY93xx13aNy4cfLw8FDjxo3VtGnTIu9b+PXXXys4ONjyuDhXqkyaNEmVK1dW7dq11bZtW0vfjzzyiNavX6+aNWvq3Llzys7Olq+vr9VVM126dFHt2rVVtWpV+fv768MPP1SPHj2UkZGh3377TdWrV7e0f++99/Tggw+qa9euqlChgrp06aK3335btWvXLvA6Nm3apPHjx6tp06by9PRUeHi4GjVqZHUvx969e6tq1aqqWrWqvLy89Msvvyg2NlY//fSTJk+ebNVWunG1+8GDBw1rDQAAAPyvevXqKSgoyOpTpjelpaWpe/fu2rFjh2Ef69ev15dffqkPPvhAn332mVauXKl69epZtbk1FD979qwmT56s6Ohoff3119q0aZPVrWXq1KmjX3/91SqI//TTT60u0rm17UMPPaRDhw5Zfnbv3q1//vOfhR4bAMozgnQAKEGnT5/Whg0brK7o+Pzzz3XmzBlLm5tXrUiSh4eHJCk/P98SLvv4+Fj233XXXYbHq1atmtXC9tYrW/7Xr7/+ahVMF+dKlerVqxfa99WrV/XCCy+oXbt2GjNmjN577z2ZzWbl5+db2t965Yqnp6d27NihLl26qH///lq8eLHS0tIsi/tz586pbt26VuNt1aqVqlSpUuB1nD59WgsWLLCqcVJSklWNbz12//799fzzz+uzzz5TWFiYunfvrnfeeceqzzp16ui3334rtG4AAACAkeeff17/93//p+XLl+vixYsym836z3/+oyeffFLNmze33KKxKBkZGfLw8JCnp6fy8vL0/vvva//+/UV+T1BmZqauX78ub29vSVJycrLlk565ubnq1q2b8vLytGrVKuXm5iolJUXz5s1TTk6OJKlSpUq6cuWKJCk8PFw7duzQgQMHlJ+fr1OnTumxxx7T2rVrS6o8AOA2PJw9AABwJ3Xq1FFYWJieeOIJy7YzZ87Iy8vrts+tW7eu0tPTdfXqVcui+NZw+I+qUKGCVdB965UqN8P0Tz/9VBkZGbrzzjsN+3ruuedUrVo1HThwQJUrV1Z+fr7atm1r1ebWgH7Xrl3auHGj3nnnHf3pT3+SJM2ZM0cnTpyQJN15550FXuvatWutrqC/ddxRUVHq37+/ZVtKSorVR2VvPfZPP/2k5s2bKywsTNnZ2froo4/097//XaGhoQoMDJQkXb9+XRUq8G/LAAAAsF27du20ceNGrVq1Sv3799fVq1cVEBCgPn36aPz48fL09DR8/ujRo3XixAl1795dlStXVrNmzTRs2DCr2ybe6p577tHTTz+t6dOn6+rVq6pTp44eeeQRvfLKKzpx4oRatGihmJgYzZ8/X+vWrZO3t7ceffRRRURESJIiIiI0depUjRw5UtHR0Vq8eLEWL16syZMny9vbWwMGDNDf/va3Eq8TALg6gnQAsEN6enqBK5gDAgL0yCOP6OWXX1aHDh3UqlUrJSYmaty4cYqMjLT6ks/C3HvvvWrcuLH+8Y9/aMaMGfr999+1dOlSqza3Xj1iq7p161rdeqVbt276xz/+oVWrVmnMmDH67bffNG/ePI0fP/62fWVkZKhWrVqqUKGCMjIytHz5cmVkZBR51cyVK1dUoUIFeXl5yWw2a//+/XrvvfcsQfZDDz2kUaNG6cCBA7r//vv15ZdfatmyZdqyZYsyMzMtfVSpUkWPPPKIXn/9dTVt2lSNGjXS/v37FRkZqddee00PPPBAgWPv2bNHmzdvVkxMjO666y75+fnJw8PD6mr3wq6IBwAAAIqrVatWWrlyZZH7jx8/bvV4yJAhGjJkiKQb905ftWpVkc+dNGlSgW1jxozRmDFjrLaNGDHC8t9//vOftWHDhkL7e+655/Tcc89ZHnfr1q3QLyKVpH/84x9FjgsAyhuCdACww5QpUwps27lzp/r06aOsrCw988wzOnPmjPz8/DRy5EgNHz78tn1WqFBBS5cu1Ysvvqj77rtPderUUY8ePfSf//zH0ubWq0duXtldXB07dtTcuXMtj6tWrVrklSpxcXGGfT333HOWW7v4+vqqW7du6ty5s+UK8//10EMP6fDhw+rfv78qVqyoe+65RyNGjNCmTZuUm5urNm3aaMGCBVqwYIFOnz6tevXqafHixQoMDFRWVpbatGmjzp07a8mSJRo5cqTMZrMiIyN17tw51a5dWy+88EKhIbokPf744zp79qz+8pe/KCMjQ/Xq1dOrr75qdQubw4cPq1+/fjbVEwAAAAAAlB8m863fPgEAcJrs7GwlJCSoXbt2qlixoiTp888/14svvqj9+/f/4f5zc3P1wAMPaPny5br33nv/cH/u4rffftPAgQO1e/du+fv7O3s4AAAAAACgDOKGsABQRnh6emrKlCnasmWL8vPzlZaWprVr16p79+4l0n+lSpUUFRWldevWlUh/7mLDhg0aPnw4IToAAAAAACgSQToAlBEVK1bUihUrtG3bNrVt21YDBw5UYGCgZsyYUWLHCA8P19WrV3Xo0KES69OVpaSk6MiRI3ryySedPRQAAAAAAFCGcWsXAAAAAAAAAAAMcEU6AAAAAAAAAAAGCNIBAAAAAAAAADBAkA4AAAAAAAAAgAGCdAAAAAAAAAAADBCkAwAAAAAAAABggCAdAAAAAAAAAAADBOkAAAAAAAAAABggSAcAAAAAAAAAwMD/By7hE9ewmS1VAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Label distribution\n",
    "df['label'].value_counts().plot(kind='bar', ax=axes[0, 0], color='steelblue')\n",
    "axes[0, 0].set_title('Label Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Label')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Class distribution (top 10)\n",
    "df['class'].value_counts().head(10).plot(kind='barh', ax=axes[0, 1], color='coral')\n",
    "axes[0, 1].set_title('Top 10 Trademark Classes', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Count')\n",
    "axes[0, 1].set_ylabel('Class')\n",
    "\n",
    "# Wordmark length distribution\n",
    "axes[1, 0].hist(df['wordmark_length'], bins=30, color='mediumseagreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Wordmark Length Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Length (characters)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Character distribution (first character)\n",
    "first_chars = df['wordmark'].str[0].str.upper().value_counts().head(15)\n",
    "first_chars.plot(kind='bar', ax=axes[1, 1], color='mediumpurple')\n",
    "axes[1, 1].set_title('Top 15 Starting Characters', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Character')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b899fb9",
   "metadata": {},
   "source": [
    "# 2. Text Preprocessing Pipeline\n",
    "\n",
    "Build robust preprocessing functions that normalize text while preserving original forms for phonetic analysis and language detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1c7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     - ------------------------------------ 30.7/981.5 kB 87.5 kB/s eta 0:00:11\n",
      "     - ------------------------------------ 30.7/981.5 kB 87.5 kB/s eta 0:00:11\n",
      "     - ------------------------------------ 41.0/981.5 kB 93.7 kB/s eta 0:00:11\n",
      "     -- ---------------------------------- 61.4/981.5 kB 131.3 kB/s eta 0:00:08\n",
      "     -- ---------------------------------- 71.7/981.5 kB 145.6 kB/s eta 0:00:07\n",
      "     --- --------------------------------- 92.2/981.5 kB 175.0 kB/s eta 0:00:06\n",
      "     ---- ------------------------------- 112.6/981.5 kB 204.8 kB/s eta 0:00:05\n",
      "     ----- ------------------------------ 143.4/981.5 kB 224.5 kB/s eta 0:00:04\n",
      "     ------- ---------------------------- 204.8/981.5 kB 296.6 kB/s eta 0:00:03\n",
      "     -------- --------------------------- 225.3/981.5 kB 320.0 kB/s eta 0:00:03\n",
      "     --------- -------------------------- 245.8/981.5 kB 328.0 kB/s eta 0:00:03\n",
      "     --------- -------------------------- 245.8/981.5 kB 328.0 kB/s eta 0:00:03\n",
      "     --------- -------------------------- 245.8/981.5 kB 328.0 kB/s eta 0:00:03\n",
      "     ------------------ ----------------- 491.5/981.5 kB 540.8 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 501.8/981.5 kB 542.5 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 501.8/981.5 kB 542.5 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 522.2/981.5 kB 489.0 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 634.9/981.5 kB 571.5 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 727.0/981.5 kB 628.8 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 716.5 kB/s eta 0:00:01\n",
      "     -----------------------------------  962.6/981.5 kB 781.9 kB/s eta 0:00:01\n",
      "     -----------------------------------  962.6/981.5 kB 781.9 kB/s eta 0:00:01\n",
      "     ------------------------------------ 981.5/981.5 kB 731.4 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Collecting textblob\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/1e/d6/40aa5aead775582ea0cf35870e5a3f16fab4b967f1ad2debe675f673f923/textblob-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: unidecode in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Collecting nltk\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/60/90/81ac364ef94209c100e12579629dc92bf7a709a84af32f8c551b02c07e94/nltk-3.9.2-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/624.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/624.3 kB 1.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 61.4/624.3 kB 1.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 61.4/624.3 kB 1.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 61.4/624.3 kB 1.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 61.4/624.3 kB 1.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 61.4/624.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  614.4/624.3 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.1/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=8545de10fb4f9ca36724a01d661ddf7eab219664403391110aca39b0596975b0\n",
      "  Stored in directory: c:\\users\\nfiu\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect, nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed langdetect-1.0.9 nltk-3.9.2 textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for language detection\n",
    "# Run this cell once\n",
    "!pip install langdetect nltk textblob unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba906cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Text Preprocessor:\n",
      "============================================================\n",
      "\n",
      "Original: TechFlow™\n",
      "Normalized: techflowtm\n",
      "Language: English\n",
      "Length: 9, Unique chars: 9\n",
      "\n",
      "Original: Café Délicieux\n",
      "Normalized: cafe delicieux\n",
      "Language: fr\n",
      "Length: 14, Unique chars: 11\n",
      "\n",
      "Original: QuickMart\n",
      "Normalized: quickmart\n",
      "Language: English\n",
      "Length: 9, Unique chars: 9\n",
      "\n",
      "Original: データSync\n",
      "Normalized: tetasync\n",
      "Language: ja\n",
      "Length: 7, Unique chars: 7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # For reproducibility\n",
    "\n",
    "# Text preprocessing functions\n",
    "class TextPreprocessor:\n",
    "    \"\"\"\n",
    "    Comprehensive text preprocessing for trademark text.\n",
    "    Maintains both normalized and original forms.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize_text(text, preserve_case=False):\n",
    "        \"\"\"\n",
    "        Normalize text: lowercasing, punctuation removal, unicode cleanup\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Unicode normalization (NFKD)\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        \n",
    "        # Remove accents while preserving characters\n",
    "        text = unidecode(text)\n",
    "        \n",
    "        # Remove special characters except spaces\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Lowercase unless preservation is requested\n",
    "        if not preserve_case:\n",
    "            text = text.lower()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_language(text):\n",
    "        \"\"\"\n",
    "        Detect language of text (EN, HA, YO, or other)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            # Map language codes\n",
    "            lang_map = {\n",
    "                'en': 'English',\n",
    "                'ha': 'Hausa',\n",
    "                'yo': 'Yoruba'\n",
    "            }\n",
    "            return lang_map.get(lang, lang)\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_character_ngrams(text, n=3):\n",
    "        \"\"\"\n",
    "        Extract character n-grams for similarity comparison\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        return [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_trademark(wordmark):\n",
    "        \"\"\"\n",
    "        Complete preprocessing pipeline for a single trademark\n",
    "        Returns dict with original, normalized, and metadata\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'original': wordmark,\n",
    "            'normalized': TextPreprocessor.normalize_text(wordmark),\n",
    "            'normalized_preserved_case': TextPreprocessor.normalize_text(wordmark, preserve_case=True),\n",
    "            'length': len(wordmark),\n",
    "            'language': TextPreprocessor.detect_language(wordmark),\n",
    "            'char_count': len(set(wordmark.lower())),\n",
    "            'has_numbers': bool(re.search(r'\\d', wordmark)),\n",
    "            'has_special': bool(re.search(r'[^\\w\\s]', wordmark))\n",
    "        }\n",
    "\n",
    "# Test the preprocessor\n",
    "print(\"Testing Text Preprocessor:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_cases = [\n",
    "    \"TechFlow™\",\n",
    "    \"Café Délicieux\",\n",
    "    \"QuickMart\",\n",
    "    \"データSync\",  # Mixed languages\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    result = TextPreprocessor.preprocess_trademark(test)\n",
    "    print(f\"\\nOriginal: {result['original']}\")\n",
    "    print(f\"Normalized: {result['normalized']}\")\n",
    "    print(f\"Language: {result['language']}\")\n",
    "    print(f\"Length: {result['length']}, Unique chars: {result['char_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e803c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing to dataset...\n",
      "\n",
      "Preprocessed dataset preview:\n",
      "  wordmark_original wordmark_normalized detected_language\n",
      "0          TechFlow            techflow           English\n",
      "1           TekFlow             tekflow           English\n",
      "2          DataSync            datasync                id\n",
      "3          DataLink            datalink                id\n",
      "4         QuickMart           quickmart           English\n",
      "5          FastMart            fastmart           English\n",
      "\n",
      "--- Language Distribution ---\n",
      "detected_language\n",
      "English    4\n",
      "id         2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to entire dataset\n",
    "print(\"Applying preprocessing to dataset...\")\n",
    "\n",
    "# Process all wordmarks\n",
    "processed_data = df['wordmark'].apply(TextPreprocessor.preprocess_trademark)\n",
    "\n",
    "# Extract components into separate columns\n",
    "df['wordmark_normalized'] = processed_data.apply(lambda x: x['normalized'])\n",
    "df['wordmark_original'] = processed_data.apply(lambda x: x['original'])\n",
    "df['detected_language'] = processed_data.apply(lambda x: x['language'])\n",
    "df['has_numbers'] = processed_data.apply(lambda x: x['has_numbers'])\n",
    "df['has_special'] = processed_data.apply(lambda x: x['has_special'])\n",
    "df['unique_chars'] = processed_data.apply(lambda x: x['char_count'])\n",
    "\n",
    "print(\"\\nPreprocessed dataset preview:\")\n",
    "print(df[['wordmark_original', 'wordmark_normalized', 'detected_language']].head(10))\n",
    "\n",
    "print(\"\\n--- Language Distribution ---\")\n",
    "print(df['detected_language'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64cdf2a",
   "metadata": {},
   "source": [
    "# 3. Character-Level CNN Architecture\n",
    "\n",
    "Design and implement a character-level CNN for extracting deep features from trademark text. This architecture is particularly effective for capturing spelling variants and misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7f1cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: torch in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Install deep learning libraries if needed\n",
    "!pip install tensorflow torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75aeaa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.0\n",
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe30213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20\n",
      "Sample characters: ['t', 'a', 'c', 'f', 'l', 'k', 'e', 'o', 'w', 'd', 's', 'n', 'i', 'm', 'r', 'h', 'y', 'q', 'u']\n",
      "\n",
      "Sequence shape: (6, 50)\n",
      "Sample sequence (first trademark):\n",
      "Text: techflow\n",
      "Sequence: [ 1  7  3 16  4  5  8  9  0  0  0  0  0  0  0  0  0  0  0  0]...\n"
     ]
    }
   ],
   "source": [
    "# Character-level tokenization setup\n",
    "class CharacterTokenizer:\n",
    "    \"\"\"\n",
    "    Converts text to character-level sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_len=50, char_level=True):\n",
    "        self.max_len = max_len\n",
    "        self.char_level = char_level\n",
    "        self.tokenizer = Tokenizer(char_level=char_level, lower=True)\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "    def fit(self, texts):\n",
    "        \"\"\"Fit tokenizer on texts\"\"\"\n",
    "        self.tokenizer.fit_on_texts(texts)\n",
    "        self.vocab_size = len(self.tokenizer.word_index) + 1\n",
    "        print(f\"Vocabulary size: {self.vocab_size}\")\n",
    "        print(f\"Sample characters: {list(self.tokenizer.word_index.keys())[:20]}\")\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        \"\"\"Transform texts to padded sequences\"\"\"\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        padded = pad_sequences(sequences, maxlen=self.max_len, padding='post')\n",
    "        return padded\n",
    "    \n",
    "    def fit_transform(self, texts):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit(texts)\n",
    "        return self.transform(texts)\n",
    "\n",
    "# Initialize and fit tokenizer\n",
    "char_tokenizer = CharacterTokenizer(max_len=50)\n",
    "X_sequences = char_tokenizer.fit_transform(df['wordmark_normalized'].values)\n",
    "\n",
    "print(f\"\\nSequence shape: {X_sequences.shape}\")\n",
    "print(f\"Sample sequence (first trademark):\")\n",
    "print(f\"Text: {df['wordmark_normalized'].iloc[0]}\")\n",
    "print(f\"Sequence: {X_sequences[0][:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd757261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character-Level CNN Architecture:\n",
      "============================================================\n",
      "Model: \"CharCNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " char_input (InputLayer)     [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " char_embedding (Embedding)  (None, 50, 64)               1280      ['char_input[0][0]']          \n",
      "                                                                                                  \n",
      " conv_2 (Conv1D)             (None, 50, 128)              16512     ['char_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " conv_3 (Conv1D)             (None, 50, 128)              24704     ['char_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " conv_4 (Conv1D)             (None, 50, 128)              32896     ['char_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " conv_5 (Conv1D)             (None, 50, 128)              41088     ['char_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " pool_2 (GlobalMaxPooling1D  (None, 128)                  0         ['conv_2[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool_3 (GlobalMaxPooling1D  (None, 128)                  0         ['conv_3[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool_4 (GlobalMaxPooling1D  (None, 128)                  0         ['conv_4[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool_5 (GlobalMaxPooling1D  (None, 128)                  0         ['conv_5[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concat (Concatenate)        (None, 512)                  0         ['pool_2[0][0]',              \n",
      "                                                                     'pool_3[0][0]',              \n",
      "                                                                     'pool_4[0][0]',              \n",
      "                                                                     'pool_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 256)                  131328    ['concat[0][0]']              \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)          (None, 256)                  0         ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_layer (Dense)     (None, 128)                  32896     ['dropout1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout2 (Dropout)          (None, 128)                  0         ['embedding_layer[0][0]']     \n",
      "                                                                                                  \n",
      " classification (Dense)      (None, 1)                    129       ['dropout2[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 280833 (1.07 MB)\n",
      "Trainable params: 280833 (1.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Character-Level CNN Architecture\n",
    "def build_char_cnn(vocab_size, max_len, embedding_dim=64, num_filters=128):\n",
    "    \"\"\"\n",
    "    Build a character-level CNN for trademark embedding extraction\n",
    "    \n",
    "    Architecture:\n",
    "    - Embedding layer\n",
    "    - Multiple Conv1D layers with different kernel sizes\n",
    "    - MaxPooling\n",
    "    - Dense layers\n",
    "    - Output: embeddings + classification head\n",
    "    \"\"\"\n",
    "    \n",
    "    input_layer = layers.Input(shape=(max_len,), name='char_input')\n",
    "    \n",
    "    # Character embedding\n",
    "    embedding = layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=max_len,\n",
    "        name='char_embedding'\n",
    "    )(input_layer)\n",
    "    \n",
    "    # Multi-scale convolutional layers (different kernel sizes)\n",
    "    conv_blocks = []\n",
    "    kernel_sizes = [2, 3, 4, 5]\n",
    "    \n",
    "    for kernel_size in kernel_sizes:\n",
    "        conv = layers.Conv1D(\n",
    "            filters=num_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            name=f'conv_{kernel_size}'\n",
    "        )(embedding)\n",
    "        pool = layers.GlobalMaxPooling1D(name=f'pool_{kernel_size}')(conv)\n",
    "        conv_blocks.append(pool)\n",
    "    \n",
    "    # Concatenate all pooled features\n",
    "    concatenated = layers.Concatenate(name='concat')(conv_blocks)\n",
    "    \n",
    "    # Dense layers\n",
    "    dense1 = layers.Dense(256, activation='relu', name='dense1')(concatenated)\n",
    "    dropout1 = layers.Dropout(0.5, name='dropout1')(dense1)\n",
    "    \n",
    "    # Embedding layer (penultimate) - this is what we'll extract for SVM\n",
    "    embedding_output = layers.Dense(128, activation='relu', name='embedding_layer')(dropout1)\n",
    "    dropout2 = layers.Dropout(0.3, name='dropout2')(embedding_output)\n",
    "    \n",
    "    # Classification head (for training)\n",
    "    output = layers.Dense(1, activation='sigmoid', name='classification')(dropout2)\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Model(inputs=input_layer, outputs=output, name='CharCNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "vocab_size = char_tokenizer.vocab_size\n",
    "max_len = char_tokenizer.max_len\n",
    "\n",
    "cnn_model = build_char_cnn(vocab_size, max_len)\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"Character-Level CNN Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dbc36a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Obtaining dependency information for pydot from https://files.pythonhosted.org/packages/7e/32/a7125fb28c4261a627f999d5fb4afff25b523800faed2c30979949d6facd/pydot-4.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyparsing>=3.1.0 (from pydot)\n",
      "  Obtaining dependency information for pyparsing>=3.1.0 from https://files.pythonhosted.org/packages/8b/40/2614036cdd416452f5bf98ec037f38a1afb17f327cb8e6b652d4729e0af8/pyparsing-3.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Downloading pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.8 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/121.8 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 41.0/121.8 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 41.0/121.8 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 41.0/121.8 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 71.7/121.8 kB 302.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 112.6/121.8 kB 437.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 121.8/121.8 kB 446.2 kB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, pydot\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "Successfully installed pydot-4.0.1 pyparsing-3.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "matplotlib 3.7.2 requires pyparsing<3.1,>=2.3.1, but you have pyparsing 3.3.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5d7c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: pydot in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Collecting pydotplus\n",
      "  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n",
      "     ---------------------------------------- 0.0/278.7 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/278.7 kB ? eta -:--:--\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -- ---------------------------------- 20.5/278.7 kB 217.9 kB/s eta 0:00:02\n",
      "     -------- ---------------------------- 61.4/278.7 kB 130.9 kB/s eta 0:00:02\n",
      "     --------- --------------------------- 71.7/278.7 kB 151.0 kB/s eta 0:00:02\n",
      "     --------- --------------------------- 71.7/278.7 kB 151.0 kB/s eta 0:00:02\n",
      "     --------- --------------------------- 71.7/278.7 kB 151.0 kB/s eta 0:00:02\n",
      "     --------- --------------------------- 71.7/278.7 kB 151.0 kB/s eta 0:00:02\n",
      "     -------------- --------------------- 112.6/278.7 kB 163.8 kB/s eta 0:00:02\n",
      "     ------------------ ----------------- 143.4/278.7 kB 198.1 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 153.6/278.7 kB 199.4 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 174.1/278.7 kB 213.9 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 184.3/278.7 kB 218.4 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 225.3/278.7 kB 250.0 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 256.0/278.7 kB 271.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 278.7/278.7 kB 281.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyparsing>=3.1.0 in c:\\users\\nfiu\\anaconda3\\lib\\site-packages (from pydot) (3.3.1)\n",
      "Building wheels for collected packages: pydotplus\n",
      "  Building wheel for pydotplus (setup.py): started\n",
      "  Building wheel for pydotplus (setup.py): finished with status 'done'\n",
      "  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24578 sha256=18a608a9cde71bd6951321bae88e8089a88486e9efc13efed2727ae9bed75504\n",
      "  Stored in directory: c:\\users\\nfiu\\appdata\\local\\pip\\cache\\wheels\\bd\\ce\\e8\\ff9d9c699514922f57caa22fbd55b0a32761114b4c4acc9e03\n",
      "Successfully built pydotplus\n",
      "Installing collected packages: pydotplus\n",
      "Successfully installed pydotplus-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install pydot pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fd70074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'cnn_architecture.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    971\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m method(include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1035\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m   1034\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[1;32m-> 1035\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_and_metadata(always_both\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[0;32m   1037\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'cnn_architecture.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'cnn_architecture.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m method()\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1067\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[1;32m-> 1067\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_and_metadata()\n",
      "File \u001b[1;32mc:\\Users\\NFIU\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'cnn_architecture.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "# Plot and display immediately\n",
    "tf.keras.utils.plot_model(cnn_model, to_file='cnn_architecture.png', show_shapes=True)\n",
    "display(Image('cnn_architecture.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0c25cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "✓ Model architecture diagram saved as 'cnn_architecture.png'\n"
     ]
    }
   ],
   "source": [
    "# Visualize model architecture\n",
    "keras.utils.plot_model(\n",
    "    cnn_model,\n",
    "    to_file='cnn_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=96\n",
    ")\n",
    "\n",
    "print(\"✓ Model architecture diagram saved as 'cnn_architecture.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3764ecc",
   "metadata": {},
   "source": [
    "# 4. CNN Training and Embedding Extraction\n",
    "\n",
    "Train the CNN on labeled trademark data and extract embeddings from the penultimate layer for downstream SVM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989690d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare training data\n",
    "# For this demo with sample data, we'll create synthetic labels\n",
    "# In production, use your actual pairwise similarity labels\n",
    "\n",
    "# Create pairwise dataset for training\n",
    "# For simplicity, we'll train on individual marks first\n",
    "X = X_sequences\n",
    "y = df['label'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "print(f\"\\nLabel distribution in training set:\")\n",
    "print(f\"Class 0: {np.sum(y_train == 0)}\")\n",
    "print(f\"Class 1: {np.sum(y_train == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for training\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_cnn_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# NOTE: With sample data, training may not be meaningful\n",
    "# This demonstrates the training pipeline\n",
    "print(\"Starting CNN training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For demonstration with small sample data, use fewer epochs\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,  # Increase to 50-100 for real data\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Training Precision', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation Precision', linewidth=2)\n",
    "axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Training Recall', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation Recall', linewidth=2)\n",
    "axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1669136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from penultimate layer\n",
    "# Create a new model that outputs the embedding layer\n",
    "embedding_extractor = models.Model(\n",
    "    inputs=cnn_model.input,\n",
    "    outputs=cnn_model.get_layer('embedding_layer').output,\n",
    "    name='EmbeddingExtractor'\n",
    ")\n",
    "\n",
    "print(\"Embedding Extractor Model:\")\n",
    "embedding_extractor.summary()\n",
    "\n",
    "# Extract embeddings for all data\n",
    "print(\"\\nExtracting embeddings...\")\n",
    "train_embeddings = embedding_extractor.predict(X_train, verbose=0)\n",
    "val_embeddings = embedding_extractor.predict(X_val, verbose=0)\n",
    "test_embeddings = embedding_extractor.predict(X_test, verbose=0)\n",
    "\n",
    "print(f\"\\nEmbedding shapes:\")\n",
    "print(f\"Training embeddings: {train_embeddings.shape}\")\n",
    "print(f\"Validation embeddings: {val_embeddings.shape}\")\n",
    "print(f\"Test embeddings: {test_embeddings.shape}\")\n",
    "\n",
    "# Store embeddings in dataframe for later use\n",
    "df['cnn_embedding'] = list(embedding_extractor.predict(X_sequences, verbose=0))\n",
    "print(f\"\\n✓ Embeddings extracted and stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90bf1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Computing t-SNE visualization of embeddings...\")\n",
    "\n",
    "# Combine train and validation for visualization\n",
    "all_embeddings = np.vstack([train_embeddings, val_embeddings])\n",
    "all_labels = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(all_embeddings)-1))\n",
    "embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0], \n",
    "    embeddings_2d[:, 1],\n",
    "    c=all_labels,\n",
    "    cmap='viridis',\n",
    "    alpha=0.6,\n",
    "    s=100,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "plt.colorbar(scatter, label='Label')\n",
    "plt.title('t-SNE Visualization of CNN Embeddings', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('t-SNE Component 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Component 2', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ t-SNE visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc580b05",
   "metadata": {},
   "source": [
    "# 5. Linguistic Feature Engineering - Synonyms & Antonyms\n",
    "\n",
    "Build synonym and antonym expansion features using WordNet for English and custom lexicons for Hausa/Yoruba languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29efdbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NLP libraries\n",
    "# !pip install nltk spacy sentence-transformers\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa993dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "print(\"✓ NLTK resources loaded\")\n",
    "\n",
    "# Load multilingual sentence embedding model\n",
    "print(\"\\nLoading multilingual sentence transformer...\")\n",
    "semantic_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "print(\"✓ Sentence transformer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynonymAntonymEngine:\n",
    "    \"\"\"\n",
    "    Extract synonyms and antonyms for English, Hausa, and Yoruba\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Custom lexicons for Hausa and Yoruba\n",
    "        # In production, load from comprehensive lexicon files\n",
    "        self.hausa_lexicon = {\n",
    "            'quick': ['sauri', 'gaggawa'],\n",
    "            'fast': ['sauri', 'gaggawa'],\n",
    "            'good': ['mai kyau', 'kyakkyawa'],\n",
    "            'shop': ['shago', 'kantin'],\n",
    "            'market': ['kasuwa'],\n",
    "            'food': ['abinci'],\n",
    "            'tech': ['fasaha'],\n",
    "            'data': ['bayanai']\n",
    "        }\n",
    "        \n",
    "        self.yoruba_lexicon = {\n",
    "            'quick': ['yara', 'kiakia'],\n",
    "            'fast': ['yara', 'kiakia'],\n",
    "            'good': ['dara', 'rere'],\n",
    "            'shop': ['ile itaja', 'itaja'],\n",
    "            'market': ['oja'],\n",
    "            'food': ['onje'],\n",
    "            'tech': ['imọ-ẹrọ'],\n",
    "            'data': ['data']\n",
    "        }\n",
    "        \n",
    "    def get_synonyms_en(self, word):\n",
    "        \"\"\"Get English synonyms using WordNet\"\"\"\n",
    "        synonyms = set()\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.add(lemma.name().lower().replace('_', ' '))\n",
    "        return list(synonyms)\n",
    "    \n",
    "    def get_antonyms_en(self, word):\n",
    "        \"\"\"Get English antonyms using WordNet\"\"\"\n",
    "        antonyms = set()\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms():\n",
    "                    antonyms.add(lemma.antonyms()[0].name().lower().replace('_', ' '))\n",
    "        return list(antonyms)\n",
    "    \n",
    "    def get_hausa_equivalents(self, word):\n",
    "        \"\"\"Get Hausa equivalents from lexicon\"\"\"\n",
    "        word_lower = word.lower()\n",
    "        return self.hausa_lexicon.get(word_lower, [])\n",
    "    \n",
    "    def get_yoruba_equivalents(self, word):\n",
    "        \"\"\"Get Yoruba equivalents from lexicon\"\"\"\n",
    "        word_lower = word.lower()\n",
    "        return self.yoruba_lexicon.get(word_lower, [])\n",
    "    \n",
    "    def expand_trademark(self, trademark_text):\n",
    "        \"\"\"\n",
    "        Expand a trademark into synonyms, antonyms, and translations\n",
    "        \"\"\"\n",
    "        words = trademark_text.lower().split()\n",
    "        \n",
    "        expansion = {\n",
    "            'synonyms': [],\n",
    "            'antonyms': [],\n",
    "            'hausa': [],\n",
    "            'yoruba': []\n",
    "        }\n",
    "        \n",
    "        for word in words:\n",
    "            expansion['synonyms'].extend(self.get_synonyms_en(word))\n",
    "            expansion['antonyms'].extend(self.get_antonyms_en(word))\n",
    "            expansion['hausa'].extend(self.get_hausa_equivalents(word))\n",
    "            expansion['yoruba'].extend(self.get_yoruba_equivalents(word))\n",
    "        \n",
    "        # Remove duplicates\n",
    "        for key in expansion:\n",
    "            expansion[key] = list(set(expansion[key]))\n",
    "        \n",
    "        return expansion\n",
    "\n",
    "# Initialize engine\n",
    "syn_ant_engine = SynonymAntonymEngine()\n",
    "\n",
    "# Test the engine\n",
    "print(\"Testing Synonym/Antonym Engine:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_marks = ['QuickMart', 'FastFood', 'GoodTech', 'DataShop']\n",
    "\n",
    "for mark in test_marks:\n",
    "    expansion = syn_ant_engine.expand_trademark(mark)\n",
    "    print(f\"\\n{mark}:\")\n",
    "    print(f\"  Synonyms: {expansion['synonyms'][:5]}\")\n",
    "    print(f\"  Antonyms: {expansion['antonyms'][:5]}\")\n",
    "    print(f\"  Hausa: {expansion['hausa']}\")\n",
    "    print(f\"  Yoruba: {expansion['yoruba']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synonym_overlap(mark1, mark2, engine):\n",
    "    \"\"\"\n",
    "    Compute overlap score between expanded synonym sets\n",
    "    \"\"\"\n",
    "    exp1 = engine.expand_trademark(mark1)\n",
    "    exp2 = engine.expand_trademark(mark2)\n",
    "    \n",
    "    # Combine all expansions\n",
    "    set1 = set(exp1['synonyms'] + exp1['hausa'] + exp1['yoruba'] + [mark1.lower()])\n",
    "    set2 = set(exp2['synonyms'] + exp2['hausa'] + exp2['yoruba'] + [mark2.lower()])\n",
    "    \n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Jaccard similarity\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def compute_semantic_similarity(mark1, mark2, model):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity using sentence embeddings\n",
    "    \"\"\"\n",
    "    embeddings = model.encode([mark1, mark2])\n",
    "    \n",
    "    # Cosine similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    \n",
    "    return float(similarity)\n",
    "\n",
    "# Compute pairwise features for sample data\n",
    "print(\"Computing synonym and semantic features...\")\n",
    "\n",
    "# For demonstration, compute for first few pairs\n",
    "sample_pairs = [\n",
    "    ('TechFlow', 'TekFlow'),\n",
    "    ('DataSync', 'DataLink'),\n",
    "    ('QuickMart', 'FastMart')\n",
    "]\n",
    "\n",
    "results = []\n",
    "for mark1, mark2 in sample_pairs:\n",
    "    overlap = compute_synonym_overlap(mark1, mark2, syn_ant_engine)\n",
    "    semantic_sim = compute_semantic_similarity(mark1, mark2, semantic_model)\n",
    "    \n",
    "    results.append({\n",
    "        'mark1': mark1,\n",
    "        'mark2': mark2,\n",
    "        'synonym_overlap': overlap,\n",
    "        'semantic_similarity': semantic_sim\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{mark1} ↔ {mark2}\")\n",
    "    print(f\"  Synonym overlap: {overlap:.3f}\")\n",
    "    print(f\"  Semantic similarity: {semantic_sim:.3f}\")\n",
    "\n",
    "# Create dataframe\n",
    "syn_features_df = pd.DataFrame(results)\n",
    "print(\"\\n✓ Synonym and semantic features computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad464ef",
   "metadata": {},
   "source": [
    "# 6. Linguistic Feature Engineering - Phonetic Similarity\n",
    "\n",
    "Implement phonetic encoding and similarity measures to capture pronunciation-based similarity between trademarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install phonetic libraries\n",
    "# !pip install phonetics jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "class PhoneticSimilarityEngine:\n",
    "    \"\"\"\n",
    "    Compute phonetic similarity using multiple algorithms\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def double_metaphone_encode(text):\n",
    "        \"\"\"Get Double Metaphone encoding\"\"\"\n",
    "        primary, secondary = jellyfish.metaphone(text), jellyfish.metaphone(text)\n",
    "        return primary, secondary\n",
    "    \n",
    "    @staticmethod\n",
    "    def soundex_encode(text):\n",
    "        \"\"\"Get Soundex encoding\"\"\"\n",
    "        try:\n",
    "            return jellyfish.soundex(text)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def match_rating_encode(text):\n",
    "        \"\"\"Get Match Rating Codex\"\"\"\n",
    "        try:\n",
    "            return jellyfish.match_rating_codex(text)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_phonetic_similarity(mark1, mark2):\n",
    "        \"\"\"\n",
    "        Compute comprehensive phonetic similarity metrics\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 1. Double Metaphone\n",
    "        dm1_pri, dm1_sec = PhoneticSimilarityEngine.double_metaphone_encode(mark1)\n",
    "        dm2_pri, dm2_sec = PhoneticSimilarityEngine.double_metaphone_encode(mark2)\n",
    "        features['metaphone_match'] = int(dm1_pri == dm2_pri or dm1_pri == dm2_sec or \n",
    "                                          dm1_sec == dm2_pri or dm1_sec == dm2_sec)\n",
    "        \n",
    "        # 2. Soundex\n",
    "        sdx1 = PhoneticSimilarityEngine.soundex_encode(mark1)\n",
    "        sdx2 = PhoneticSimilarityEngine.soundex_encode(mark2)\n",
    "        features['soundex_match'] = int(sdx1 == sdx2) if sdx1 and sdx2 else 0\n",
    "        \n",
    "        # 3. Levenshtein distance on phonetic codes\n",
    "        if dm1_pri and dm2_pri:\n",
    "            features['metaphone_distance'] = levenshtein_distance(dm1_pri, dm2_pri)\n",
    "        else:\n",
    "            features['metaphone_distance'] = 999\n",
    "        \n",
    "        # 4. Jaro-Winkler similarity (good for brand names)\n",
    "        features['jaro_winkler'] = jellyfish.jaro_winkler_similarity(mark1.lower(), mark2.lower())\n",
    "        \n",
    "        # 5. Match Rating Comparison\n",
    "        try:\n",
    "            features['match_rating_comparison'] = int(jellyfish.match_rating_comparison(mark1, mark2))\n",
    "        except:\n",
    "            features['match_rating_comparison'] = 0\n",
    "        \n",
    "        # 6. Raw Levenshtein distance\n",
    "        features['levenshtein_distance'] = levenshtein_distance(mark1.lower(), mark2.lower())\n",
    "        \n",
    "        # 7. Normalized Levenshtein similarity\n",
    "        max_len = max(len(mark1), len(mark2))\n",
    "        features['normalized_levenshtein'] = 1 - (features['levenshtein_distance'] / max_len) if max_len > 0 else 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_char_ngram_similarity(mark1, mark2, n=3):\n",
    "        \"\"\"\n",
    "        Character n-gram cosine similarity\n",
    "        \"\"\"\n",
    "        def get_ngrams(text, n):\n",
    "            text = text.lower()\n",
    "            return [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "        \n",
    "        ngrams1 = set(get_ngrams(mark1, n))\n",
    "        ngrams2 = set(get_ngrams(mark2, n))\n",
    "        \n",
    "        if not ngrams1 or not ngrams2:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = len(ngrams1 & ngrams2)\n",
    "        union = len(ngrams1 | ngrams2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Initialize engine\n",
    "phonetic_engine = PhoneticSimilarityEngine()\n",
    "\n",
    "# Test phonetic similarity\n",
    "print(\"Testing Phonetic Similarity Engine:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_pairs = [\n",
    "    ('TechFlow', 'TekFlow'),\n",
    "    ('QuickMart', 'KwikMart'),\n",
    "    ('DataSync', 'DataLink'),\n",
    "    ('FastFood', 'FirstFood')\n",
    "]\n",
    "\n",
    "for mark1, mark2 in test_pairs:\n",
    "    features = phonetic_engine.compute_phonetic_similarity(mark1, mark2)\n",
    "    ngram_sim = phonetic_engine.compute_char_ngram_similarity(mark1, mark2)\n",
    "    \n",
    "    print(f\"\\n{mark1} ↔ {mark2}\")\n",
    "    print(f\"  Metaphone match: {features['metaphone_match']}\")\n",
    "    print(f\"  Soundex match: {features['soundex_match']}\")\n",
    "    print(f\"  Jaro-Winkler: {features['jaro_winkler']:.3f}\")\n",
    "    print(f\"  Normalized Levenshtein: {features['normalized_levenshtein']:.3f}\")\n",
    "    print(f\"  Char 3-gram similarity: {ngram_sim:.3f}\")\n",
    "    print(f\"  Raw Levenshtein distance: {features['levenshtein_distance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute phonetic features for sample pairs\n",
    "print(\"\\nComputing phonetic features for all sample pairs...\")\n",
    "\n",
    "phonetic_results = []\n",
    "\n",
    "for mark1, mark2 in sample_pairs:\n",
    "    features = phonetic_engine.compute_phonetic_similarity(mark1, mark2)\n",
    "    features['char_trigram_sim'] = phonetic_engine.compute_char_ngram_similarity(mark1, mark2, n=3)\n",
    "    features['char_bigram_sim'] = phonetic_engine.compute_char_ngram_similarity(mark1, mark2, n=2)\n",
    "    features['mark1'] = mark1\n",
    "    features['mark2'] = mark2\n",
    "    \n",
    "    phonetic_results.append(features)\n",
    "\n",
    "phonetic_df = pd.DataFrame(phonetic_results)\n",
    "\n",
    "print(\"\\nPhonetic Features Summary:\")\n",
    "print(phonetic_df[['mark1', 'mark2', 'jaro_winkler', 'normalized_levenshtein', \n",
    "                   'char_trigram_sim', 'metaphone_match']])\n",
    "\n",
    "print(\"\\n✓ Phonetic features computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7cfc68",
   "metadata": {},
   "source": [
    "# 7. Linguistic Feature Engineering - Hausa & Yoruba Translation\n",
    "\n",
    "Build translation lexicons and compute cross-lingual semantic similarity for Hausa and Yoruba languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualTranslationEngine:\n",
    "    \"\"\"\n",
    "    Handle Hausa and Yoruba translations and cross-lingual similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Expanded business domain lexicons\n",
    "        # In production, load from comprehensive dictionary files\n",
    "        self.en_to_hausa = {\n",
    "            'market': 'kasuwa',\n",
    "            'shop': 'shago',\n",
    "            'store': 'kantin sayarwa',\n",
    "            'quick': 'sauri',\n",
    "            'fast': 'gaggawa',\n",
    "            'good': 'mai kyau',\n",
    "            'best': 'mafi kyau',\n",
    "            'tech': 'fasaha',\n",
    "            'technology': 'fasahar zamani',\n",
    "            'data': 'bayanai',\n",
    "            'food': 'abinci',\n",
    "            'service': 'hidima',\n",
    "            'link': 'hanyar haɗi',\n",
    "            'sync': 'daidaitawa',\n",
    "            'flow': 'gudana',\n",
    "            'smart': 'mai hankali',\n",
    "            'digital': 'dijital',\n",
    "            'online': 'akan layi',\n",
    "            'mobile': 'wayar hannu'\n",
    "        }\n",
    "        \n",
    "        self.en_to_yoruba = {\n",
    "            'market': 'oja',\n",
    "            'shop': 'ile itaja',\n",
    "            'store': 'ile itaja',\n",
    "            'quick': 'yara',\n",
    "            'fast': 'kiakia',\n",
    "            'good': 'dara',\n",
    "            'best': 'to dara ju',\n",
    "            'tech': 'imọ-ẹrọ',\n",
    "            'technology': 'imọ-ẹrọ',\n",
    "            'data': 'data',\n",
    "            'food': 'onje',\n",
    "            'service': 'iṣẹ',\n",
    "            'link': 'asopọ',\n",
    "            'sync': 'muṣiṣẹpọ',\n",
    "            'flow': 'ṣiṣan',\n",
    "            'smart': 'ọlọgbọn',\n",
    "            'digital': 'alagbeka',\n",
    "            'online': 'lori ayelujara',\n",
    "            'mobile': 'alagbeka'\n",
    "        }\n",
    "        \n",
    "        # Reverse mappings\n",
    "        self.hausa_to_en = {v: k for k, v in self.en_to_hausa.items()}\n",
    "        self.yoruba_to_en = {v: k for k, v in self.en_to_yoruba.items()}\n",
    "    \n",
    "    def translate_to_hausa(self, text):\n",
    "        \"\"\"Translate English words to Hausa\"\"\"\n",
    "        words = text.lower().split()\n",
    "        translations = []\n",
    "        \n",
    "        for word in words:\n",
    "            # Clean word\n",
    "            word_clean = ''.join(c for c in word if c.isalnum())\n",
    "            translation = self.en_to_hausa.get(word_clean, word_clean)\n",
    "            translations.append(translation)\n",
    "        \n",
    "        return ' '.join(translations)\n",
    "    \n",
    "    def translate_to_yoruba(self, text):\n",
    "        \"\"\"Translate English words to Yoruba\"\"\"\n",
    "        words = text.lower().split()\n",
    "        translations = []\n",
    "        \n",
    "        for word in words:\n",
    "            word_clean = ''.join(c for c in word if c.isalnum())\n",
    "            translation = self.en_to_yoruba.get(word_clean, word_clean)\n",
    "            translations.append(translation)\n",
    "        \n",
    "        return ' '.join(translations)\n",
    "    \n",
    "    def compute_cross_lingual_similarity(self, mark1, mark2, semantic_model):\n",
    "        \"\"\"\n",
    "        Compute similarity considering translations\n",
    "        \"\"\"\n",
    "        # Get translations\n",
    "        mark1_ha = self.translate_to_hausa(mark1)\n",
    "        mark1_yo = self.translate_to_yoruba(mark1)\n",
    "        mark2_ha = self.translate_to_hausa(mark2)\n",
    "        mark2_yo = self.translate_to_yoruba(mark2)\n",
    "        \n",
    "        # Compute embeddings for all versions\n",
    "        texts = [mark1, mark2, mark1_ha, mark2_ha, mark1_yo, mark2_yo]\n",
    "        embeddings = semantic_model.encode(texts)\n",
    "        \n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        # Original similarity\n",
    "        sim_original = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "        \n",
    "        # Hausa cross-lingual\n",
    "        sim_ha_cross = max(\n",
    "            cosine_similarity([embeddings[0]], [embeddings[3]])[0][0],  # mark1 vs mark2_ha\n",
    "            cosine_similarity([embeddings[2]], [embeddings[1]])[0][0]   # mark1_ha vs mark2\n",
    "        )\n",
    "        \n",
    "        # Yoruba cross-lingual\n",
    "        sim_yo_cross = max(\n",
    "            cosine_similarity([embeddings[0]], [embeddings[5]])[0][0],  # mark1 vs mark2_yo\n",
    "            cosine_similarity([embeddings[4]], [embeddings[1]])[0][0]   # mark1_yo vs mark2\n",
    "        )\n",
    "        \n",
    "        # Same-language translated similarity\n",
    "        sim_ha_ha = cosine_similarity([embeddings[2]], [embeddings[3]])[0][0]\n",
    "        sim_yo_yo = cosine_similarity([embeddings[4]], [embeddings[5]])[0][0]\n",
    "        \n",
    "        return {\n",
    "            'original_similarity': float(sim_original),\n",
    "            'hausa_cross_similarity': float(sim_ha_cross),\n",
    "            'yoruba_cross_similarity': float(sim_yo_cross),\n",
    "            'hausa_translation_similarity': float(sim_ha_ha),\n",
    "            'yoruba_translation_similarity': float(sim_yo_yo),\n",
    "            'max_cross_lingual': float(max(sim_ha_cross, sim_yo_cross)),\n",
    "            'mark1_hausa': mark1_ha,\n",
    "            'mark1_yoruba': mark1_yo,\n",
    "            'mark2_hausa': mark2_ha,\n",
    "            'mark2_yoruba': mark2_yo\n",
    "        }\n",
    "\n",
    "# Initialize translation engine\n",
    "translation_engine = MultilingualTranslationEngine()\n",
    "\n",
    "# Test translations\n",
    "print(\"Testing Multilingual Translation Engine:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_marks = ['QuickMart', 'FastFood', 'TechStore', 'DataLink']\n",
    "\n",
    "for mark in test_marks:\n",
    "    hausa = translation_engine.translate_to_hausa(mark)\n",
    "    yoruba = translation_engine.translate_to_yoruba(mark)\n",
    "    \n",
    "    print(f\"\\n{mark}:\")\n",
    "    print(f\"  Hausa: {hausa}\")\n",
    "    print(f\"  Yoruba: {yoruba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-lingual features for sample pairs\n",
    "print(\"\\nComputing cross-lingual similarity features...\")\n",
    "\n",
    "cross_lingual_results = []\n",
    "\n",
    "for mark1, mark2 in sample_pairs:\n",
    "    features = translation_engine.compute_cross_lingual_similarity(\n",
    "        mark1, mark2, semantic_model\n",
    "    )\n",
    "    features['mark1'] = mark1\n",
    "    features['mark2'] = mark2\n",
    "    \n",
    "    cross_lingual_results.append(features)\n",
    "    \n",
    "    print(f\"\\n{mark1} ↔ {mark2}\")\n",
    "    print(f\"  Original: {features['original_similarity']:.3f}\")\n",
    "    print(f\"  Hausa cross: {features['hausa_cross_similarity']:.3f}\")\n",
    "    print(f\"  Yoruba cross: {features['yoruba_cross_similarity']:.3f}\")\n",
    "    print(f\"  Max cross-lingual: {features['max_cross_lingual']:.3f}\")\n",
    "\n",
    "cross_lingual_df = pd.DataFrame(cross_lingual_results)\n",
    "\n",
    "print(\"\\n✓ Cross-lingual features computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7bb9e",
   "metadata": {},
   "source": [
    "# 8. Feature Vector Combination\n",
    "\n",
    "Concatenate CNN embeddings with all linguistic features to create comprehensive feature vectors for SVM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "class FeatureVectorBuilder:\n",
    "    \"\"\"\n",
    "    Combine CNN embeddings with linguistic features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.fitted = False\n",
    "    \n",
    "    def build_feature_vector(self, cnn_embedding, linguistic_features):\n",
    "        \"\"\"\n",
    "        Combine CNN embedding with linguistic feature dict\n",
    "        \n",
    "        Args:\n",
    "            cnn_embedding: numpy array from CNN\n",
    "            linguistic_features: dict with all linguistic features\n",
    "        \n",
    "        Returns:\n",
    "            Combined feature vector\n",
    "        \"\"\"\n",
    "        # Extract linguistic features in consistent order\n",
    "        ling_features = [\n",
    "            # Synonym/Semantic features\n",
    "            linguistic_features.get('synonym_overlap', 0),\n",
    "            linguistic_features.get('semantic_similarity', 0),\n",
    "            \n",
    "            # Phonetic features\n",
    "            linguistic_features.get('metaphone_match', 0),\n",
    "            linguistic_features.get('soundex_match', 0),\n",
    "            linguistic_features.get('jaro_winkler', 0),\n",
    "            linguistic_features.get('normalized_levenshtein', 0),\n",
    "            linguistic_features.get('levenshtein_distance', 0),\n",
    "            linguistic_features.get('char_trigram_sim', 0),\n",
    "            linguistic_features.get('char_bigram_sim', 0),\n",
    "            linguistic_features.get('match_rating_comparison', 0),\n",
    "            \n",
    "            # Cross-lingual features\n",
    "            linguistic_features.get('original_similarity', 0),\n",
    "            linguistic_features.get('hausa_cross_similarity', 0),\n",
    "            linguistic_features.get('yoruba_cross_similarity', 0),\n",
    "            linguistic_features.get('hausa_translation_similarity', 0),\n",
    "            linguistic_features.get('yoruba_translation_similarity', 0),\n",
    "            linguistic_features.get('max_cross_lingual', 0)\n",
    "        ]\n",
    "        \n",
    "        # Combine\n",
    "        combined = np.concatenate([cnn_embedding, ling_features])\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def fit_transform(self, embeddings_list, linguistic_features_list):\n",
    "        \"\"\"\n",
    "        Fit scaler and transform features\n",
    "        \"\"\"\n",
    "        # Build all feature vectors\n",
    "        feature_vectors = []\n",
    "        for emb, ling in zip(embeddings_list, linguistic_features_list):\n",
    "            vec = self.build_feature_vector(emb, ling)\n",
    "            feature_vectors.append(vec)\n",
    "        \n",
    "        feature_vectors = np.array(feature_vectors)\n",
    "        \n",
    "        # Fit and transform\n",
    "        scaled_features = self.scaler.fit_transform(feature_vectors)\n",
    "        self.fitted = True\n",
    "        \n",
    "        return scaled_features\n",
    "    \n",
    "    def transform(self, embeddings_list, linguistic_features_list):\n",
    "        \"\"\"\n",
    "        Transform features using fitted scaler\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler not fitted. Call fit_transform first.\")\n",
    "        \n",
    "        # Build feature vectors\n",
    "        feature_vectors = []\n",
    "        for emb, ling in zip(embeddings_list, linguistic_features_list):\n",
    "            vec = self.build_feature_vector(emb, ling)\n",
    "            feature_vectors.append(vec)\n",
    "        \n",
    "        feature_vectors = np.array(feature_vectors)\n",
    "        \n",
    "        # Transform\n",
    "        scaled_features = self.scaler.transform(feature_vectors)\n",
    "        \n",
    "        return scaled_features\n",
    "\n",
    "# Initialize feature builder\n",
    "feature_builder = FeatureVectorBuilder()\n",
    "\n",
    "print(\"Feature Vector Builder initialized\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comprehensive feature dataset\n",
    "# For demo purposes, we'll create synthetic pairwise features\n",
    "\n",
    "print(\"Building comprehensive feature vectors...\")\n",
    "\n",
    "# Combine all linguistic features for sample pairs\n",
    "all_linguistic_features = []\n",
    "\n",
    "for i in range(len(sample_pairs)):\n",
    "    combined_features = {\n",
    "        **syn_features_df.iloc[i].to_dict(),\n",
    "        **phonetic_df.iloc[i].to_dict(),\n",
    "        **cross_lingual_df.iloc[i].to_dict()\n",
    "    }\n",
    "    all_linguistic_features.append(combined_features)\n",
    "\n",
    "# For demonstration, use embeddings from first marks in each pair\n",
    "# In production, you would compute pairwise embeddings (e.g., concatenate or difference)\n",
    "sample_embeddings = [\n",
    "    train_embeddings[0],  # TechFlow embedding\n",
    "    train_embeddings[1],  # DataSync embedding  \n",
    "    train_embeddings[2]   # QuickMart embedding\n",
    "]\n",
    "\n",
    "# Build combined feature vectors\n",
    "combined_features = feature_builder.fit_transform(\n",
    "    sample_embeddings,\n",
    "    all_linguistic_features\n",
    ")\n",
    "\n",
    "print(f\"\\nCombined feature shape: {combined_features.shape}\")\n",
    "print(f\"  - CNN embedding dimensions: 128\")\n",
    "print(f\"  - Linguistic feature dimensions: {combined_features.shape[1] - 128}\")\n",
    "print(f\"  - Total dimensions: {combined_features.shape[1]}\")\n",
    "\n",
    "# Show feature statistics\n",
    "feature_df = pd.DataFrame(combined_features)\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(feature_df.describe())\n",
    "\n",
    "print(\"\\n✓ Feature vectors built and normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance through correlation\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Create sample labels for correlation\n",
    "sample_labels = [1, 1, 1]  # All similar for demo\n",
    "\n",
    "# Compute correlations\n",
    "correlation_data = np.column_stack([combined_features, sample_labels])\n",
    "correlation_df = pd.DataFrame(correlation_data)\n",
    "correlation_df.columns = [f'F{i}' for i in range(combined_features.shape[1])] + ['Label']\n",
    "\n",
    "# Plot correlation with label\n",
    "correlations = correlation_df.corr()['Label'].drop('Label').sort_values(ascending=False)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "correlations.head(20).plot(kind='barh', color='steelblue')\n",
    "plt.title('Top 20 Features Correlated with Similarity Label', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Correlation with Label')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(combined_features.flatten(), bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of All Feature Values (Normalized)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136021b7",
   "metadata": {},
   "source": [
    "# 9. SVM Classifier Training\n",
    "\n",
    "Train SVM classifiers on the combined feature vectors and compare performance between CNN-only and CNN+linguistic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9123860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "print(\"Preparing SVM training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For this demonstration with limited sample data, we'll create synthetic training data\n",
    "# In production, use your actual labeled pairwise trademark data\n",
    "\n",
    "# Create synthetic training data for demonstration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate more samples for meaningful training\n",
    "n_similar = 100\n",
    "n_dissimilar = 100\n",
    "\n",
    "# Similar pairs: high feature values\n",
    "X_similar = np.random.randn(n_similar, combined_features.shape[1]) * 0.5 + 1.5\n",
    "y_similar = np.ones(n_similar)\n",
    "\n",
    "# Dissimilar pairs: low feature values\n",
    "X_dissimilar = np.random.randn(n_dissimilar, combined_features.shape[1]) * 0.5 - 1.5\n",
    "y_dissimilar = np.zeros(n_dissimilar)\n",
    "\n",
    "# Combine\n",
    "X_train_svm = np.vstack([X_similar, X_dissimilar])\n",
    "y_train_svm = np.concatenate([y_similar, y_dissimilar])\n",
    "\n",
    "# Shuffle\n",
    "shuffle_idx = np.random.permutation(len(X_train_svm))\n",
    "X_train_svm = X_train_svm[shuffle_idx]\n",
    "y_train_svm = y_train_svm[shuffle_idx]\n",
    "\n",
    "# Split into train/val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_svm, X_val_svm, y_train_svm, y_val_svm = train_test_split(\n",
    "    X_train_svm, y_train_svm, test_size=0.2, random_state=42, stratify=y_train_svm\n",
    ")\n",
    "\n",
    "print(f\"SVM Training set: {X_train_svm.shape}\")\n",
    "print(f\"SVM Validation set: {X_val_svm.shape}\")\n",
    "print(f\"Label distribution (train): Similar={np.sum(y_train_svm)}, Dissimilar={np.sum(y_train_svm==0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with Linear Kernel\n",
    "print(\"\\n1. Training Linear SVM...\")\n",
    "\n",
    "svm_linear = SVC(kernel='linear', C=1.0, probability=True, random_state=42)\n",
    "svm_linear.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_linear = svm_linear.predict(X_val_svm)\n",
    "train_score_linear = svm_linear.score(X_train_svm, y_train_svm)\n",
    "val_score_linear = svm_linear.score(X_val_svm, y_val_svm)\n",
    "\n",
    "print(f\"Linear SVM - Training Accuracy: {train_score_linear:.4f}\")\n",
    "print(f\"Linear SVM - Validation Accuracy: {val_score_linear:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Linear SVM):\")\n",
    "print(classification_report(y_val_svm, y_pred_linear, \n",
    "                          target_names=['Dissimilar', 'Similar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with RBF Kernel\n",
    "print(\"\\n2. Training RBF SVM...\")\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "svm_rbf.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rbf = svm_rbf.predict(X_val_svm)\n",
    "train_score_rbf = svm_rbf.score(X_train_svm, y_train_svm)\n",
    "val_score_rbf = svm_rbf.score(X_val_svm, y_val_svm)\n",
    "\n",
    "print(f\"RBF SVM - Training Accuracy: {train_score_rbf:.4f}\")\n",
    "print(f\"RBF SVM - Validation Accuracy: {val_score_rbf:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (RBF SVM):\")\n",
    "print(classification_report(y_val_svm, y_pred_rbf,\n",
    "                          target_names=['Dissimilar', 'Similar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "print(\"\\n3. Hyperparameter Tuning...\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_svm, y_train_svm)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Best model\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_val_svm)\n",
    "val_score_best = best_svm.score(X_val_svm, y_val_svm)\n",
    "\n",
    "print(f\"\\nBest SVM - Validation Accuracy: {val_score_best:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Best SVM):\")\n",
    "print(classification_report(y_val_svm, y_pred_best,\n",
    "                          target_names=['Dissimilar', 'Similar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e40b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CNN-only vs CNN+Linguistic Features\n",
    "print(\"\\n4. Comparing CNN-only vs CNN+Linguistic...\")\n",
    "\n",
    "# CNN-only features (first 128 dimensions)\n",
    "X_train_cnn_only = X_train_svm[:, :128]\n",
    "X_val_cnn_only = X_val_svm[:, :128]\n",
    "\n",
    "# Train SVM on CNN-only\n",
    "svm_cnn_only = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
    "svm_cnn_only.fit(X_train_cnn_only, y_train_svm)\n",
    "\n",
    "val_score_cnn_only = svm_cnn_only.score(X_val_cnn_only, y_val_svm)\n",
    "\n",
    "# Compare\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Linear SVM', 'RBF SVM', 'Best SVM (Tuned)', 'CNN-only SVM'],\n",
    "    'Validation Accuracy': [val_score_linear, val_score_rbf, val_score_best, val_score_cnn_only]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(comparison_df['Model'], comparison_df['Validation Accuracy'], \n",
    "        color=['steelblue', 'coral', 'mediumseagreen', 'mediumpurple'])\n",
    "plt.title('SVM Model Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Validation Accuracy', fontsize=12)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim([0, 1.1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(comparison_df['Validation Accuracy']):\n",
    "    plt.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ SVM training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607acd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "print(\"\\nSaving trained models...\")\n",
    "\n",
    "# Save best SVM\n",
    "joblib.dump(best_svm, 'best_svm_model.pkl')\n",
    "print(\"✓ Best SVM saved: best_svm_model.pkl\")\n",
    "\n",
    "# Save CNN embedding extractor\n",
    "embedding_extractor.save('cnn_embedding_extractor.h5')\n",
    "print(\"✓ CNN embedding extractor saved: cnn_embedding_extractor.h5\")\n",
    "\n",
    "# Save feature scaler\n",
    "joblib.dump(feature_builder.scaler, 'feature_scaler.pkl')\n",
    "print(\"✓ Feature scaler saved: feature_scaler.pkl\")\n",
    "\n",
    "print(\"\\n✓ All models saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210323f",
   "metadata": {},
   "source": [
    "# 10. Model Evaluation and Metrics\n",
    "\n",
    "Comprehensive evaluation using accuracy, precision, recall, F1-score, ROC-AUC, and confusion matrices. Prioritize recall for confusingly similar cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
